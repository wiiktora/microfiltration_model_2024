{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37918.76495752991\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize_scalar\n",
    "import numpy as np\n",
    "from Bio.SeqUtils.IsoelectricPoint import IsoelectricPoint as IP\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "import re\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "import copy\n",
    "import time\n",
    "from scipy.integrate import solve_ivp\n",
    "L= 0.135 # module length in meters\n",
    "n_f = 6 #number of fibers\n",
    "A = 0.0032 #m2\n",
    "i_d = 1.27e-3#internal diameter m\n",
    "delta_membrane = 0.325e-3 #m\n",
    "p_s = 0.1e-6 #pore size in meters\n",
    "T = 298 #K\n",
    "R = 8.314 #J/mol/K\n",
    "F = 96485 #C/mol\n",
    "e = 1.60217662e-19 #C\n",
    "porosity = 0.80\n",
    "X = 1\n",
    "pH =9\n",
    "permitivity = 6.375e-10 #permitivity of the medium C^2(J.m)^-1\n",
    "I = 7.5 #ionic strength mM\n",
    "# gamma_w = 32400#shear rate s-1\n",
    "phi_m = 0.68\n",
    "eta_0 = 0.000905#Pa.second viscosity of hte TGM\n",
    "rho_p = 1300 #kg/m3 density of the particles\n",
    "rho_f = 1000 #kg/m3 density of the fluid\n",
    "k_B = 1.38064852e-23 #J/mol/K Boltzmann constant\n",
    "phi_w_guess = [0.64,0.64,0.64] #guess for the volume fraction of solute at the membrane wall\n",
    "Re = 3000\n",
    "\n",
    "\n",
    "# Particle sizes (in meters)\n",
    "particles = [\n",
    "    {'name': '10nm', 'radius': 10e-9, 'phi_b': 0.01*X},\n",
    "    {'name': '180nm', 'radius': 180e-9, 'phi_b': 0.05*X},\n",
    "    {'name': '300nm', 'radius': 300e-9, 'phi_b': 0.06*X}\n",
    "]\n",
    "phi_w_dict={key:values for key, values in zip([particle['radius'] for particle in particles], phi_w_guess)}\n",
    "target_species = 10e-9 \n",
    "#equations\n",
    "#Step 2 - evaluate the viscosity\n",
    "    # no particle-particle interactions - dillute suspensions\n",
    "def viscosity_no_PP(eta_0,phi_b,k1):\n",
    "    \"\"\"eta_0 - viscosity of the dispersion medium\n",
    "    phi - volume in parts occupied by the dispersed solid\n",
    "    k1 = shape factor\"\"\"\n",
    "    if phi_b<0.1:\n",
    "        eta_phi = eta_0*(1+(5/2)*phi_b)\n",
    "    elif phi_b>0.1:\n",
    "        eta_phi = eta_0*(1+(5/2)*phi_b+k1*(phi_b**2))\n",
    "    return eta_phi\n",
    "  \n",
    "\n",
    "def max_agg_packing (phi_m):\n",
    "    phi_Max=phi_m+0.74*(1-phi_m)\n",
    "    return phi_Max\n",
    "phi_M = max_agg_packing(phi_m)\n",
    "eta_f= viscosity_no_PP(eta_0,0.12*X,10)\n",
    "V_ax = Re*eta_f/(rho_f*i_d) \n",
    "gamma_w = (8*V_ax)*1.95/i_d\n",
    "print(gamma_w)\n",
    "\n",
    "\n",
    "def J_brownian(a, phi_w, phi_b):\n",
    "    numerator = gamma_w * (k_B ** 2) * (T ** 2)\n",
    "    denominator = (eta_f ** 2) * (a ** 2) * L\n",
    "    term = (numerator / denominator) ** (1/3)\n",
    "    J = 0.114 * term * (math.log((abs(phi_w / phi_b))))\n",
    "    return J\n",
    "\n",
    "# Function to calculate J for shear-induced diffusion\n",
    "def J_shear(a, phi_w, phi_b):\n",
    "    term = (a ** 4 / L) ** (1/3)\n",
    "    log_term = math.log(abs(phi_w / phi_b))\n",
    "    J = 0.078 * term * gamma_w * (log_term)\n",
    "    return J\n",
    "\n",
    "# Function to calculate J for inertial lift\n",
    "def J_inertial(a):\n",
    "    J = (0.036 * rho_p * (a ** 3) * (gamma_w ** 2)) / eta_f\n",
    "    return J\n",
    "#J solvent permeation flux (m/s)\n",
    "\n",
    "\n",
    "def get_protein_info(uniprot_code, pH):\n",
    "    Entrez.email = \"s230152@dtu.dk\"\n",
    "    handle = Entrez.esearch(db=\"protein\", term=uniprot_code, retmax=1)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    protein_id = record[\"IdList\"][0]\n",
    "\n",
    "    handle = Entrez.efetch(db=\"protein\", id=protein_id, rettype=\"gb\", retmode=\"text\")\n",
    "    record = handle.read()\n",
    "    handle.close()\n",
    "\n",
    "    seq_record = SeqIO.read(StringIO(record), \"genbank\")\n",
    "    protein_sequence = seq_record.seq\n",
    "    protein = IP(protein_sequence)\n",
    "\n",
    "    iep = protein.pi()\n",
    "    net_charge = protein.charge_at_pH(pH)\n",
    "\n",
    "    return iep, net_charge\n",
    "uniprot_code = {a:uniprot_code for a,uniprot_code in zip([particle['name'] for particle in particles],['P0DOX5','P02768','P05814'])}\n",
    "net_charge = {}\n",
    "for particle in particles:\n",
    "    particle['iep'], particle['net_charge'] = get_protein_info(uniprot_code[particle['name']], pH)\n",
    "    net_charge[particle['name']] = particle['net_charge']\n",
    "# net_charge = {'10nm': 11.43, '180nm': -10.63, '300nm': -4.67} #ph 6.8\n",
    "# L_p =(porosity*(p_s)**2)/(8*eta_f*delta_membrane)\n",
    "L_p= 99/3600/1000/1000   \n",
    "s = (( 5*eta_f* delta_membrane * L_p) /porosity)**(1/2)\n",
    "k = (((permitivity*R*T)/(((F**2)*(2*I))))**(1/2))\n",
    "lambda_aph_dict={}\n",
    "for particle,charge in zip(particles,net_charge.values()):\n",
    "    z = charge\n",
    "    phi_b = particle['phi_b']\n",
    "    a = particle['radius']\n",
    "    lambda_aph = 1 - math.exp(-a/(2*s))\n",
    "    \n",
    "    delta_s = ((z)*e)/(4*math.pi*(a**2))\n",
    "    eff_a = a + (((4*(a**3)*(delta_s**2))/(permitivity*k_B*T))*0.2*k)\n",
    "    particle[\"radius\"]=eff_a\n",
    "    lambda_aph_dict[eff_a] = lambda_aph\n",
    "# print(lambda_aph_dict)\n",
    "target_species = particles[0]['radius']\n",
    "phi_w_dict={key:values for key, values in zip([particle['radius'] for particle in particles], phi_w_guess)}\n",
    "set_data = pd.DataFrame(columns=['name', 'radius', 'max_velocity', 'source'])\n",
    "\n",
    "\n",
    "def min_flux(Particles, phi_w_list):\n",
    "    \"\"\" have to put particles list with radius and phi_b,\n",
    "    phi_w_list with phi_w\n",
    "    results ai_target, J_flux and dataframe\"\"\"\n",
    "    \n",
    "    min_velocity = float('inf')\n",
    "    selected_particle_radius = None\n",
    "    velocities_list=[]\n",
    "\n",
    "    for particle, phi_w in zip(Particles, phi_w_list):\n",
    "        a = particle['radius']\n",
    "        phi_b = particle['phi_b']\n",
    "        \n",
    "        # Calculate velocities\n",
    "        brownian_velocity = J_brownian(a, phi_w, phi_b)\n",
    "        shear_velocity = J_shear(a, phi_w, phi_b)\n",
    "        inertial_velocity = J_inertial(a)\n",
    "        \n",
    "        # Find the maximum velocity\n",
    "        max_velocity = max(brownian_velocity, inertial_velocity, shear_velocity)\n",
    "        \n",
    "        # Determine the source of the maximum velocity\n",
    "        source = 'brownian' if max_velocity == brownian_velocity else 'inertial' if max_velocity == inertial_velocity else 'shear'\n",
    "        \n",
    "        # Update set_data by replacing previous row or adding a new one\n",
    "        if particle['name'] in set_data['name'].values:\n",
    "            set_data.loc[set_data['name'] == particle['name'], ['radius', 'max_velocity', 'source']] = [a, max_velocity, source]\n",
    "        else:\n",
    "            set_data.loc[len(set_data)] = [particle['name'], a, max_velocity, source]\n",
    "       \n",
    "        # Check for the minimum velocity\n",
    "        if max_velocity < min_velocity:\n",
    "            min_velocity = max_velocity\n",
    "            selected_particle_radius = a\n",
    "\n",
    "    return selected_particle_radius, min_velocity, set_data\n",
    "\n",
    "# Initialize variables for particles and inertial-lift properties\n",
    "# ai_target, min_vel, dataf= min_flux(particles, phi_w_guess)\n",
    "\n",
    "# Function to calculate φ_w for each particle size\n",
    "def calculate_phi_w(Particles, a_target, min_velocity, data):\n",
    "    count = 0\n",
    "    # Dictionaries to store results\n",
    "    phi_w_J_dict = {}\n",
    "    phi_wjI_dict = {}\n",
    "    inertial_particles = []\n",
    "    \n",
    "    for particle in Particles:\n",
    "        a_particle = particle['radius']\n",
    "        phi_b_particle = particle['phi_b']\n",
    "        \n",
    "        if a_particle != a_target:\n",
    "            # Retrieve the velocity source from the data DataFrame\n",
    "            source = data.loc[data['radius'] == a_particle, 'source'].values[0]\n",
    "            \n",
    "            max_velocity = data.loc[data['radius'] == a_particle, 'max_velocity'].values[0]\n",
    "            if max_velocity >= 10 * min_velocity:\n",
    "                # Handle inertial particles\n",
    "                phi_wjI = 0\n",
    "                phi_wjI_dict[a_particle] = phi_wjI\n",
    "                phi_w_dict[a_particle] = phi_wjI\n",
    "                phi_w_J_dict[a_particle] = phi_wjI\n",
    "                inertial_particles.append((a_particle, phi_b_particle, max_velocity))\n",
    "            if source == \"inertial\":\n",
    "                count += 1\n",
    "            else:\n",
    "\n",
    "                    def objective_function(phi_w_particle):\n",
    "                        max_velocity = max(J_brownian(a_particle, phi_w_particle, phi_b_particle),J_shear(a_particle, phi_w_particle, phi_b_particle))\n",
    "                        return abs(max_velocity - min_velocity)\n",
    "               \n",
    "            #     # Minimize the objective function to find the optimal phi_w for the particle\n",
    "                    if a_particle == min(phi_w_dict.keys()):\n",
    "                        result = minimize_scalar(objective_function, bounds=(0, 0.74), method='bounded')\n",
    "                    else:\n",
    "                        result = minimize_scalar(objective_function, bounds=(0, 0.64), method='bounded')\n",
    "\n",
    "                    if result.success:\n",
    "                        phi_w_optimal = result.x\n",
    "                        phi_w_dict[a_particle] = phi_w_optimal\n",
    "                        phi_w_J_dict[a_particle] = phi_w_optimal\n",
    "                    else:\n",
    "                        print(f\"Optimization failed for particle radius {a_particle:.1e} m\")\n",
    "    # Handle inertial particles after processing all particles\n",
    "    if count == 1:\n",
    "        for a, phi_b, u_j in inertial_particles:\n",
    "            if phi_w_J_dict[a]!=0:\n",
    "                phi_wjI = phi_M - sum(phi_w_J_dict.values())\n",
    "                phi_wjI_dict[a] = phi_wjI\n",
    "                phi_w_dict[a] = phi_wjI\n",
    "    elif count > 1:\n",
    "        total_u_j_inv = sum((phi_b / u_j) for _, phi_b, u_j in inertial_particles)\n",
    "        phi_w_remaining = phi_M - sum(phi_w_J_dict.values())\n",
    "        phi_w_jI_sum = sum((phi_b / u_j) / total_u_j_inv * phi_w_remaining for _, phi_b, u_j in inertial_particles)\n",
    "        if abs(phi_M - (sum(phi_w_J_dict.values()) + phi_w_jI_sum)) > 1e-6:\n",
    "            print(\"Warning: φ_M and the sum of φ_w_j do not match closely enough.\")\n",
    "        \n",
    "        for a, phi_b, u_j in inertial_particles:\n",
    "            if phi_w_J_dict[a]!=0:\n",
    "                phi_wjI = (phi_b / u_j) / total_u_j_inv * phi_w_remaining\n",
    "                phi_wjI_dict[a] = phi_wjI\n",
    "                phi_w_dict[a] = phi_wjI\n",
    "\n",
    "    return phi_w_dict\n",
    "\n",
    "\n",
    "# Output the updated dictionary\n",
    "#print(f\"Updated phi_w_dict: {phi_w_dict}\")\n",
    "def packing_constraints(Particles, phi_w_list):\n",
    "    ai_target, min_vel, dataf= min_flux(Particles, phi_w_list)\n",
    "    \n",
    "    phi_w_updated=calculate_phi_w(Particles, ai_target, min_vel, dataf)\n",
    "    tolerance = 1e-6  # Set a tolerance for convergence\n",
    "    max_iterations = 80\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        remaining_phiw_j = {a: phi_w for a, phi_w in phi_w_updated.items() if a != min(phi_w_updated.keys())}\n",
    "        phi_w_i = phi_w_updated[ai_target] # Wall concentration of the target particle\n",
    "        # Check if packing constraints are satisfied\n",
    "        if (phi_M >= sum(phi_w_updated.values())) and (sum(remaining_phiw_j.values()) <= 0.68):\n",
    "            # print(f\"Iteration {i}: Packing constraints are met.\")\n",
    "            return phi_w_updated,   min_vel, ai_target, dataf\n",
    "        phi_w_previous = phi_w_updated.copy()\n",
    "        # Update phi_w for the target particle\n",
    "        phi_w_i_corrected = phi_M * (phi_w_i / sum(phi_w_updated.values()))\n",
    "        \n",
    "        phi_w_updated[ai_target] = phi_w_i_corrected\n",
    "        phi_w_j = {a: phi_w for a, phi_w in remaining_phiw_j.items() if a != ai_target}\n",
    "        if (sum(remaining_phiw_j.values()) <= 0.68)==False and ai_target in remaining_phiw_j.keys() and i>10:\n",
    "            phi_w_updated[ai_target]=0.68 *(phi_w_updated[ai_target]/(sum(remaining_phiw_j.values())))\n",
    "            # print(phi_w_updated[ai_target])\n",
    "        if (phi_w_updated[min(phi_w_updated.keys())] <= 0.74 * (1 - sum(remaining_phiw_j.values()))) == False and ai_target==min(phi_w_updated.keys())  and i>10:\n",
    "            phi_w_updated[min(phi_w_updated.keys()) ]= 0.74 * (1 - sum(remaining_phiw_j.values()))\n",
    "        # Store the previous values of phi_w for comparison\n",
    "        \n",
    "        # print(phi_w_i_corrected)\n",
    "        # Recalculate the flux and phi_w_j values after updating\n",
    "        _, min_vel, dataf= min_flux(particles, phi_w_updated.values())\n",
    "        phi_w_updated=calculate_phi_w(particles, ai_target, min_vel, dataf)\n",
    "\n",
    "        # Check for the change in phi_w values between iterations\n",
    "        phi_w_diff = sum(abs(phi_w_updated[a] - phi_w_previous[a]) for a in phi_w_updated)\n",
    "        # If the change in phi_w values is smaller than the tolerance, stop the iteration\n",
    "        if phi_w_diff < tolerance and i>50:\n",
    "            # print(f\"Iteration {i}: Will not converger further.\")\n",
    "            return phi_w_updated,   min_vel, ai_target, dataf\n",
    "    # # If the loop completes without finding a solution\n",
    "    # print(\"Warning: No solution found within the iteration limit.\")\n",
    "\n",
    "  \n",
    "    return phi_w_updated, min_vel, ai_target, dataf\n",
    "\n",
    "def J_flux_calculation(Particles, phi_w_list):\n",
    "    # Unpack the results from packing_constraints\n",
    "    phi_w_updated, J_flux, ai_target, dataf = packing_constraints(Particles, phi_w_list)\n",
    "    # print(phi_w_updated)\n",
    "    \n",
    "    # Initialize J_pi with J_flux values from packing constraints for all particles\n",
    "    J_pi = {a: J_flux for a in phi_w_updated.keys()}\n",
    "    \n",
    "    phi_w_dict_T = {}\n",
    "    phi_w_dict_R = {}\n",
    "    # Separate phi_w values into two dictionaries based on particle size comparison with p_s/2\n",
    "    for (a, phi_w) in phi_w_updated.items():\n",
    "        \n",
    "        if a <= p_s / 2:\n",
    "            phi_w_dict_T[a] = phi_w\n",
    "            # print(phi_w_dict_T)\n",
    "        else:\n",
    "            phi_w_dict_R[a] = phi_w\n",
    "            # print(phi_w_dict_R)\n",
    "\n",
    "    # Update phi_w for particles in phi_w_dict_T based on ratio of min(phi_w_dict_R.keys()) / a\n",
    "    for (a, phi_w) in phi_w_dict_T.items():\n",
    "        if (min(phi_w_dict_R.keys()) / a )< 10:\n",
    "            phi_w_updated[a] = 0.68 * (1 - sum(phi_w_dict_R.values()))\n",
    "        else:\n",
    "            phi_w_updated[a] = 0.74 * (1 - sum(phi_w_dict_R.values()))\n",
    "    \n",
    "    # Calculate J_pi only for particles in phi_w_dict_T\n",
    "    for a , particle in zip(phi_w_dict_T.keys(), Particles):\n",
    "\n",
    "        phi_b = particle['phi_b']\n",
    "        \n",
    "        # Calculate velocities\n",
    "        brownian_velocity = J_brownian(a, phi_w_updated[a], phi_b)\n",
    "        shear_velocity = J_shear(a, phi_w_updated[a], phi_b)\n",
    "        inertial_velocity = J_inertial(a)\n",
    "        \n",
    "        # Update J_pi with the maximum velocity for particles in phi_w_dict_T\n",
    "        max_velocity = max(brownian_velocity, inertial_velocity, shear_velocity)\n",
    "        J_pi[a] = max_velocity\n",
    "\n",
    "    return J_pi, phi_w_updated, J_flux, ai_target, dataf\n",
    "\n",
    "# print(J_flux_calculation(particles, phi_w_guess))\n",
    "#mass-transfer coefficient calculated from equation  1#step 10\n",
    "\n",
    "\n",
    "def sieving_parameters(Particles, phi_w_list):\n",
    "    \n",
    "    J_pi,phi_w_updated, J_flux, ai_target, dataf = J_flux_calculation(Particles, phi_w_list)\n",
    "   \n",
    "    S_oi_dep = {a: (1-(J_actual / J_pi[a])) for a in phi_w_updated.keys()}\n",
    "    S_oi_membrane = {a: 0 for a in phi_w_updated.keys()}\n",
    "    S_oi = {a: 0 for a in phi_w_updated.keys()}\n",
    "    for particle,phi_w in zip(Particles,phi_w_updated.values()):\n",
    "        phi_b = particle['phi_b']\n",
    "        a = particle['radius']\n",
    "        \n",
    "        lambda_aph =lambda_aph_dict[a]\n",
    "        # print(f\"lambda_aph: {lambda_aph}\")\n",
    "        diffusion_coeff = (k_B * T) / (6 * math.pi * eta_f * a)\n",
    "        mass_transfer_k = J_pi[a]/math.log(abs(phi_w/phi_b))\n",
    "      \n",
    "        Sieving_coeff_int = ((1 - lambda_aph) ** 2) * (2 - ((1 - lambda_aph) ** 2)) * math.exp(-0.7146 * (lambda_aph ** 2))\n",
    "        # print(f\"Initial Sieving coefficient: {Sieving_coeff_int}\")\n",
    "        phi_e_K_d = (1 - lambda_aph) ** (9 / 2)\n",
    "        # print(f\"phi_e_K_d: {phi_e_K_d}\")\n",
    "        Peclet_m = ((J_actual * (delta_membrane)) / diffusion_coeff) * (Sieving_coeff_int / (porosity * phi_e_K_d))\n",
    "        # print(f\"Peclet_m: {Peclet_m}\")\n",
    "        # print  (f\"Peclet_m: {Peclet_m}\")\n",
    "        if Peclet_m >709:\n",
    "            Sieving_coeff_act = Sieving_coeff_int\n",
    "        else:\n",
    "            Sieving_coeff_act = (Sieving_coeff_int * math.exp(Peclet_m)) / ((Sieving_coeff_int + math.exp(Peclet_m)) - 1)\n",
    "            \n",
    "        # print(f\"Actual Sieving coefficient: {Sieving_coeff_act}\")\n",
    "        Sieving_coeff_obs = Sieving_coeff_act / ((1 - Sieving_coeff_act) * math.exp(-J_actual / mass_transfer_k) + Sieving_coeff_act)\n",
    "        # print(f\"Sieving coefficient: {Sieving_coeff_obs}\")\n",
    "        S_oi_membrane[a] = Sieving_coeff_obs\n",
    "        S_oi[a] = S_oi_dep[a] * S_oi_membrane[a]\n",
    "    # print(S_oi_membrane)\n",
    "    # print(S_oi)\n",
    "    # yields = 1 - math.exp(-4 * (Sieving_coeff_obs))\n",
    "    # print(f\"Yields: {yields}\")\n",
    "            \n",
    "    return J_flux, S_oi, phi_w_updated\n",
    "# print(sieving_parameters(particles, phi_w_guess))\n",
    "J_actual = 15/ 3600 / 1000  # Actual flux in m/s\n",
    "J_PD,_,_=sieving_parameters(particles, phi_w_guess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the initial values of particles and phi_w_dict\n",
    "phi_w_dict={key:values for key, values in zip([particle['radius'] for particle in particles], phi_w_guess)}\n",
    "particles_initial = copy.deepcopy(particles)\n",
    "phi_w_dict_initial = copy.deepcopy(phi_w_dict)\n",
    "phi_b1_initial = np.array([p['phi_b'] for p in particles])  # Initial retentate concentrations\n",
    "phi_b2_initial = np.zeros(len(particles))  # Initial permeate concentrations\n",
    "# J_actual = 2/ 3600 / 1000  # Actual flux in m/s\n",
    "total_time = 50000\n",
    "V_2 = 500e-6  # Maximum permeate volume (m³)\n",
    "V_1 = 85e-6   # Feed volume (m³)\n",
    "V_R = 85e-6\n",
    "V2 =0\n",
    "# Initialize V2 globally before the simulation\n",
    " # Initial volume of permeate in the reservoir\n",
    "V2_max = V_2  # Maximum volume of permeate the reservoir can hold\n",
    "time_step = 10  # Time step in seconds\n",
    "sieving_coefficients =[]\n",
    "times = []\n",
    "# Function to calculate concentration dynamics\n",
    "def concentration_dynamics(t, y):\n",
    "   \n",
    "    # Split retentate and permeate concentrations\n",
    "    N = len(particles)\n",
    "    \n",
    "    phi_b1 = y[:N]# Retentate concentrations\n",
    "    phi_b2 = y[N:2*N]# Permeate concentrations\n",
    "    V2 = y[-1]\n",
    "    # Update particle data\n",
    "    for i, p in enumerate(particles):\n",
    "        p['phi_b'] = phi_b1[i]\n",
    "    eta_f = viscosity_no_PP(eta_0, sum(p['phi_b'] for p in particles), 10)\n",
    "    V_ax = Re * eta_f / (rho_f * i_d)\n",
    "    gamma_w = (8 * V_ax) * 1.95 / i_d\n",
    "\n",
    "# Recalculate sieving coefficients and other parameters\n",
    "    J_flux, S_oi_dict, phi_w_updated = sieving_parameters(particles, phi_w_dict.values())\n",
    "    S_oi = np.array([S_oi_dict.get(p['radius'], 0) for p in particles]) # Extract sieving coefficients\n",
    "    sieving_coefficients.append((S_oi))  # Append sieving coefficients for each particle\n",
    "    times.append(t)\n",
    "\n",
    "    # Calculate derivatives for retentate and permeate\n",
    "    dphi_b1_dt = np.zeros(len(particles))\n",
    "    dphi_b2_dt = np.zeros(len(particles))\n",
    "\n",
    "    for i, p in enumerate(particles):\n",
    "        \n",
    "        # Retentate dynamics\n",
    "        dphi_b1_dt[i] = (((A * J_actual * (- S_oi[i])))* phi_b1[i])/ V_1 \n",
    "        # Permeate dynamics\n",
    "        dphi_b2_dt[i] = (A * J_actual * S_oi[i] * phi_b1[i]) / V_2\n",
    "        dV2_dt = A * J_actual\n",
    "\n",
    "    dydt = np.concatenate([dphi_b1_dt, dphi_b2_dt, [dV2_dt]])\n",
    "    return dydt\n",
    "\n",
    "# Initial conditions\n",
    "# \n",
    "V2_initial = 0\n",
    "y0 = np.concatenate([phi_b1_initial, phi_b2_initial, [V2_initial]])\n",
    "\n",
    "def simulate_process(J_actual):\n",
    "    global sieving_coefficients\n",
    "\n",
    "    # Reset global storage\n",
    "    sieving_coefficients = []\n",
    "    # Solve the system of ODEs\n",
    "    solution = solve_ivp(\n",
    "        concentration_dynamics,\n",
    "        t_span=(0, total_time),\n",
    "        y0=y0,\n",
    "        method='RK23',\n",
    "        t_eval=np.arange(0, total_time + time_step, time_step)\n",
    "    )\n",
    "\n",
    "    # Extract results\n",
    "    time_points = solution.t\n",
    "    phi_b1_solution = solution.y[:len(particles), :].T\n",
    "    phi_b2_solution = solution.y[len(particles):2*len(particles), :].T\n",
    "    V2_solution = solution.y[-1, :].T\n",
    "\n",
    "    # Calculate cumulative yield as (phi_b2 * V_2) / (phi_b1_initial * V_1)\n",
    "    yield_fraction = (phi_b2_solution * V_2) / (phi_b1_initial * V_1)\n",
    "    # Buffer volume added (initial feed - permeate)\n",
    "    # Find when yield reaches 95%\n",
    "    stop_index = np.argmax(yield_fraction[:, 0] >= 0.95)  # Stop at first occurrence of 95%\n",
    "    if yield_fraction[stop_index, 0] < 0.95:\n",
    "        stop_index = len(time_points) - 1  # No 95% yield reached\n",
    "\n",
    "    time_reached_95 = time_points[stop_index] if stop_index < len(time_points) else None\n",
    "\n",
    "    \n",
    "    # Store results\n",
    "    results_df = pd.DataFrame({'Time (s)': time_points[:stop_index + 1]})\n",
    "    for i, p in enumerate(particles):\n",
    "        results_df[f'{p[\"name\"]}_retentate'] = phi_b1_solution[:stop_index + 1, i]\n",
    "        results_df[f'{p[\"name\"]}_permeate'] = phi_b2_solution[:stop_index + 1, i]\n",
    "        results_df[f'{p[\"name\"]}_cumulative_yield'] = yield_fraction[:stop_index + 1, i]\n",
    "        # results_df[f'{p[\"name\"]}_sieving_coefficient'] = np.array(sieving_coefficients)[:, i]\n",
    "\n",
    "\n",
    "    results_df['V2_{V_2}'] = V2_solution[:stop_index + 1]\n",
    "    results_df[\"Added Buffer\"] = results_df['V2_{V_2}']\n",
    "    results_df[\"Diavolumes\"] = results_df[\"Added Buffer\"] / V_R\n",
    "    # Split phi_w and sieving coefficients into separate columns in the results dataframe\n",
    "    # Add sieving coefficients to the results dataframe\n",
    "    sieving_df = pd.DataFrame(sieving_coefficients, columns=[f'{p[\"name\"]}_sieving_coefficient' for p in particles])\n",
    "    sieving_df['Time (s)'] = times[:len(sieving_df)]\n",
    "    \n",
    "    return results_df,  time_reached_95,sieving_df\n",
    "# Simulation loop\n",
    "J_increment = J_PD / 10  # Define increment for J_actual\n",
    "    # End timing and print the duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_actual = 15.00: Yield reached 95% in 24790.00 seconds.\n",
      "Iteration with J_actual = 15.000000000000002 completed in 1.39 seconds and\n",
      "J_actual = 19.41: Yield reached 95% in 20990.00 seconds.\n",
      "Iteration with J_actual = 19.408951106963315 completed in 0.90 seconds and\n",
      "J_actual = 23.82: Yield reached 95% in 19110.00 seconds.\n",
      "Iteration with J_actual = 23.81790221392663 completed in 1.84 seconds and\n",
      "J_actual = 28.23: Yield reached 95% in 18500.00 seconds.\n",
      "Iteration with J_actual = 28.226853320889944 completed in 2.47 seconds and\n",
      "Error during simulation for J_actual = 9.065501e-06: math range error\n",
      "Iteration with J_actual = 32.63580442785326 completed in 39.83 seconds and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/x1/1094qf1d4c1g3_6s3f1qxk_h0000gn/T/ipykernel_87002/1320218572.py\", line 11, in <module>\n",
      "    results_df, time_to_95, sieving_df= simulate_process(J_actual)\n",
      "  File \"/var/folders/x1/1094qf1d4c1g3_6s3f1qxk_h0000gn/T/ipykernel_87002/10858169.py\", line 67, in simulate_process\n",
      "    solution = solve_ivp(\n",
      "  File \"/Users/baochikhuc/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/ivp.py\", line 655, in solve_ivp\n",
      "    message = solver.step()\n",
      "  File \"/Users/baochikhuc/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/base.py\", line 197, in step\n",
      "    success, message = self._step_impl()\n",
      "  File \"/Users/baochikhuc/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/rk.py\", line 144, in _step_impl\n",
      "    y_new, f_new = rk_step(self.fun, t, y, self.f, h, self.A,\n",
      "  File \"/Users/baochikhuc/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/rk.py\", line 64, in rk_step\n",
      "    K[s] = fun(t + c * h, y + dy)\n",
      "  File \"/Users/baochikhuc/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/base.py\", line 154, in fun\n",
      "    return self.fun_single(t, y)\n",
      "  File \"/Users/baochikhuc/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/base.py\", line 23, in fun_wrapped\n",
      "    return np.asarray(fun(t, y), dtype=dtype)\n",
      "  File \"/var/folders/x1/1094qf1d4c1g3_6s3f1qxk_h0000gn/T/ipykernel_87002/10858169.py\", line 36, in concentration_dynamics\n",
      "    J_flux, S_oi_dict, phi_w_updated = sieving_parameters(particles, phi_w_dict.values())\n",
      "  File \"/var/folders/x1/1094qf1d4c1g3_6s3f1qxk_h0000gn/T/ipykernel_87002/3727585636.py\", line 367, in sieving_parameters\n",
      "    Sieving_coeff_obs = Sieving_coeff_act / ((1 - Sieving_coeff_act) * math.exp(-J_actual / mass_transfer_k) + Sieving_coeff_act)\n",
      "OverflowError: math range error\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m phi_w_dict \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(phi_w_dict_initial)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Run the simulation\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     results_df, time_to_95, sieving_df\u001b[38;5;241m=\u001b[39m \u001b[43msimulate_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ_actual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# If yield reaches 95%, store results\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_to_95 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[33], line 67\u001b[0m, in \u001b[0;36msimulate_process\u001b[0;34m(J_actual)\u001b[0m\n\u001b[1;32m     65\u001b[0m sieving_coefficients \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Solve the system of ODEs\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43msolve_ivp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcentration_dynamics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRK23\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Extract results\u001b[39;00m\n\u001b[1;32m     76\u001b[0m time_points \u001b[38;5;241m=\u001b[39m solution\u001b[38;5;241m.\u001b[39mt\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/ivp.py:655\u001b[0m, in \u001b[0;36msolve_ivp\u001b[0;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[1;32m    653\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    658\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/base.py:197\u001b[0m, in \u001b[0;36mOdeSolver.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt\n\u001b[0;32m--> 197\u001b[0m     success, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/rk.py:144\u001b[0m, in \u001b[0;36mRungeKutta._step_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m h \u001b[38;5;241m=\u001b[39m t_new \u001b[38;5;241m-\u001b[39m t\n\u001b[1;32m    142\u001b[0m h_abs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(h)\n\u001b[0;32m--> 144\u001b[0m y_new, f_new \u001b[38;5;241m=\u001b[39m \u001b[43mrk_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m scale \u001b[38;5;241m=\u001b[39m atol \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(np\u001b[38;5;241m.\u001b[39mabs(y), np\u001b[38;5;241m.\u001b[39mabs(y_new)) \u001b[38;5;241m*\u001b[39m rtol\n\u001b[1;32m    147\u001b[0m error_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_error_norm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK, h, scale)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/rk.py:67\u001b[0m, in \u001b[0;36mrk_step\u001b[0;34m(fun, t, y, f, h, A, B, C, K)\u001b[0m\n\u001b[1;32m     64\u001b[0m     K[s] \u001b[38;5;241m=\u001b[39m fun(t \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m*\u001b[39m h, y \u001b[38;5;241m+\u001b[39m dy)\n\u001b[1;32m     66\u001b[0m y_new \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m h \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(K[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT, B)\n\u001b[0;32m---> 67\u001b[0m f_new \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m K[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m f_new\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_new, f_new\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/base.py:154\u001b[0m, in \u001b[0;36mOdeSolver.__init__.<locals>.fun\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m(t, y):\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/base.py:23\u001b[0m, in \u001b[0;36mcheck_arguments.<locals>.fun_wrapped\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(t, y):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "Cell \u001b[0;32mIn[33], line 36\u001b[0m, in \u001b[0;36mconcentration_dynamics\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     33\u001b[0m     gamma_w \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m \u001b[38;5;241m*\u001b[39m V_ax) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.95\u001b[39m \u001b[38;5;241m/\u001b[39m i_d\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Recalculate sieving coefficients and other parameters\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     J_flux, S_oi_dict, phi_w_updated \u001b[38;5;241m=\u001b[39m \u001b[43msieving_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_w_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     S_oi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([S_oi_dict\u001b[38;5;241m.\u001b[39mget(p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradius\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m particles]) \u001b[38;5;66;03m# Extract sieving coefficients\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     sieving_coefficients\u001b[38;5;241m.\u001b[39mappend((S_oi))  \u001b[38;5;66;03m# Append sieving coefficients for each particle\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 340\u001b[0m, in \u001b[0;36msieving_parameters\u001b[0;34m(Particles, phi_w_list)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msieving_parameters\u001b[39m(Particles, phi_w_list):\n\u001b[0;32m--> 340\u001b[0m     J_pi,phi_w_updated, J_flux, ai_target, dataf \u001b[38;5;241m=\u001b[39m \u001b[43mJ_flux_calculation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_w_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     S_oi_dep \u001b[38;5;241m=\u001b[39m {a: (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m(J_actual \u001b[38;5;241m/\u001b[39m J_pi[a])) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m phi_w_updated\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[1;32m    343\u001b[0m     S_oi_membrane \u001b[38;5;241m=\u001b[39m {a: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m phi_w_updated\u001b[38;5;241m.\u001b[39mkeys()}\n",
      "Cell \u001b[0;32mIn[32], line 293\u001b[0m, in \u001b[0;36mJ_flux_calculation\u001b[0;34m(Particles, phi_w_list)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mJ_flux_calculation\u001b[39m(Particles, phi_w_list):\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# Unpack the results from packing_constraints\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     phi_w_updated, J_flux, ai_target, dataf \u001b[38;5;241m=\u001b[39m \u001b[43mpacking_constraints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_w_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# print(phi_w_updated)\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# Initialize J_pi with J_flux values from packing constraints for all particles\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     J_pi \u001b[38;5;241m=\u001b[39m {a: J_flux \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m phi_w_updated\u001b[38;5;241m.\u001b[39mkeys()}\n",
      "Cell \u001b[0;32mIn[32], line 276\u001b[0m, in \u001b[0;36mpacking_constraints\u001b[0;34m(Particles, phi_w_list)\u001b[0m\n\u001b[1;32m    271\u001b[0m     phi_w_updated[\u001b[38;5;28mmin\u001b[39m(phi_w_updated\u001b[38;5;241m.\u001b[39mkeys()) ]\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.74\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m(remaining_phiw_j\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Store the previous values of phi_w for comparison\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# print(phi_w_i_corrected)\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Recalculate the flux and phi_w_j values after updating\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m _, min_vel, dataf\u001b[38;5;241m=\u001b[39m \u001b[43mmin_flux\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_w_updated\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m phi_w_updated\u001b[38;5;241m=\u001b[39mcalculate_phi_w(particles, ai_target, min_vel, dataf)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Check for the change in phi_w values between iterations\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 164\u001b[0m, in \u001b[0;36mmin_flux\u001b[0;34m(Particles, phi_w_list)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Update set_data by replacing previous row or adding a new one\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m particle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m set_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[0;32m--> 164\u001b[0m     \u001b[43mset_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mset_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparticle\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mradius\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_velocity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [a, max_velocity, source]\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     set_data\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(set_data)] \u001b[38;5;241m=\u001b[39m [particle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], a, max_velocity, source]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:1942\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1941\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1942\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:2016\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;66;03m# We are setting multiple columns in a single row.\u001b[39;00m\n\u001b[1;32m   2015\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loc, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ilocs, value):\n\u001b[0;32m-> 2016\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(pi) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;66;03m# This is a setitem-with-expansion, see\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;66;03m#  test_loc_setitem_empty_append_expands_rows_mixed_dtype\u001b[39;00m\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;66;03m# e.g. df = DataFrame(columns=[\"x\", \"y\"])\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m     \u001b[38;5;66;03m#  df[\"x\"] = df[\"x\"].astype(np.int64)\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m#  df.loc[:, \"x\"] = [1, 2, 3]\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(ilocs[\u001b[38;5;241m0\u001b[39m], value, pi)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:2164\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[0;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[1;32m   2160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39misetitem(loc, value)\n\u001b[1;32m   2161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2162\u001b[0m     \u001b[38;5;66;03m# set value into the column (first attempting to operate inplace, then\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m     \u001b[38;5;66;03m#  falling back to casting if necessary)\u001b[39;00m\n\u001b[0;32m-> 2164\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mvoid:\n\u001b[1;32m   2166\u001b[0m         \u001b[38;5;66;03m# This means we're expanding, with multiple columns, e.g.\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m         \u001b[38;5;66;03m#     df = pd.DataFrame({'A': [1,2,3], 'B': [4,5,6]})\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[38;5;66;03m# Here, we replace those temporary `np.void` columns with\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m         \u001b[38;5;66;03m# columns of the appropriate dtype, based on `value`.\u001b[39;00m\n\u001b[1;32m   2172\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[:, loc] \u001b[38;5;241m=\u001b[39m construct_1d_array_from_inferred_fill_value(\n\u001b[1;32m   2173\u001b[0m             value, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   2174\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:1737\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m   1735\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n\u001b[0;32m-> 1737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/common.py:125\u001b[0m, in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_bool_indexer\u001b[39m(key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    Check whether `key` is a valid boolean indexer.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        and convert to an ndarray.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mABCSeries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCIndex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCExtensionArray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, ABCMultiIndex):\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    129\u001b[0m             key_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/generic.py:42\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(inst, attr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m comp\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# error: 'classmethod' used with a non-method\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check(inst) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subclasscheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Raise instead of returning False\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# This is consistent with default __subclasscheck__ behavior\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "while J_actual <= J_PD*1.1:\n",
    "    # Start timing the iteration\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Reset particles and phi_w_dict to their initial values\n",
    "    particles = copy.deepcopy(particles_initial)\n",
    "    phi_w_dict = copy.deepcopy(phi_w_dict_initial)\n",
    "\n",
    "    try:\n",
    "        # Run the simulation\n",
    "        results_df, time_to_95, sieving_df= simulate_process(J_actual)\n",
    "\n",
    "        # If yield reaches 95%, store results\n",
    "        if time_to_95 is not None:\n",
    "            print(f\"J_actual = {J_actual*3600*+1000:.2f}: Yield reached 95% in {time_to_95:.2f} seconds.\")\n",
    "            \n",
    "           \n",
    "\n",
    "            # Save results for this iteration with J_actual in the filename\n",
    "            results_df.to_csv(f'///Users/baochikhuc/Documents/microfiltration_model_2024/Model/Data Global Model Re = {Re}/dynamic_simulation_J_actual_{J_actual*3600*1000:.2f}_Re{Re}_X{X}.csv', index=False)\n",
    "            sieving_df.to_csv(f'//Users/baochikhuc/Documents/microfiltration_model_2024/Model/Data Global Model Re = {Re}/sieving_coefficients_J_actual_{J_actual*3600*1000:.2f}_Re{Re}_X{X}.csv', index=False)\n",
    "        else:\n",
    "            print(f\"J_actual = {J_actual:.6e}: Yield did not reach 95%. Moving to next J_actual.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error during simulation for J_actual = {J_actual:.6e}: {e}\")\n",
    "        traceback.print_exc()\n",
    "    end_time = time.time()\n",
    "    print(f\"Iteration with J_actual = {J_actual*3600*1000} completed in {end_time - start_time:.2f} seconds and\")\n",
    "\n",
    "    # Increment J_actual for the next iteration\n",
    "    J_actual += J_increment\n",
    "    \n",
    "    if J_actual <1.1 * J_PD and J_actual >  J_PD:\n",
    "        J_actual = J_PD\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
