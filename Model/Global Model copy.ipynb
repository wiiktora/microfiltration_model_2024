{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize_scalar\n",
    "import numpy as np\n",
    "from Bio.SeqUtils.IsoelectricPoint import IsoelectricPoint as IP\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "import re\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from scipy.integrate import solve_ivp\n",
    "#data\n",
    "L= 0.135 # module length in meters\n",
    "n_f = 6 #number of fibers\n",
    "A = 0.0032 #m2\n",
    "i_d = 1.27e-3#internal diameter m\n",
    "delta_membrane = 0.325e-3 #m\n",
    "p_s = 0.1e-6 #pore size in meters\n",
    "T = 298 #K\n",
    "V_1 = 50e-6 #m3\n",
    "V_2 = 500e-6 #m3\n",
    "R = 8.314 #J/mol/K\n",
    "F = 96485 #C/mol\n",
    "e = 1.60217662e-19 #C\n",
    "porosity = 65 \n",
    "pH =9\n",
    "permitivity = 6.375e-10 #permitivity of the medium C^2(J.m)^-1\n",
    "I = 7.5 #ionic strength mM\n",
    "# gamma_w = 32400#shear rate s-1\n",
    "phi_m = 0.68\n",
    "eta_0 = 0.000905#Pa.second viscosity of hte TGM\n",
    "rho_p = 1300 #kg/m3 density of the particles\n",
    "rho_f = 1000 #kg/m3 density of the fluid\n",
    "k_B = 1.38064852e-23 #J/mol/K Boltzmann constant\n",
    "phi_w_guess = [0.64,0.64,0.64] #guess for the volume fraction of solute at the membrane wall\n",
    "\n",
    "Re = 977\n",
    "# Particle sizes (in meters)\n",
    "particles = [\n",
    "    {'name': '10nm', 'radius': 10e-9, 'phi_b': 0.01},\n",
    "    {'name': '180nm', 'radius': 180e-9, 'phi_b': 0.05},\n",
    "    {'name': '300nm', 'radius': 300e-9, 'phi_b': 0.06}\n",
    "]\n",
    "phi_w_dict={key:values for key, values in zip([particle['radius'] for particle in particles], phi_w_guess)}\n",
    "target_species = 10e-9 \n",
    "#equations\n",
    "#Step 2 - evaluate the viscosity\n",
    "    # no particle-particle interactions - dillute suspensions\n",
    "def viscosity_no_PP(eta_0,phi_b,k1):\n",
    "    \"\"\"eta_0 - viscosity of the dispersion medium\n",
    "    phi - volume in parts occupied by the dispersed solid\n",
    "    k1 = shape factor\"\"\"\n",
    "    if phi_b<0.1:\n",
    "        eta_phi = eta_0*(1+5/2*phi_b)\n",
    "    elif phi_b>0.1:\n",
    "        eta_phi = eta_0*(1+5/2*phi_b+k1*phi_b**2)\n",
    "    return eta_phi\n",
    "  \n",
    "\n",
    "def max_agg_packing (phi_m):\n",
    "    phi_Max=phi_m+0.74*(1-phi_m)\n",
    "    return phi_Max\n",
    "phi_M = max_agg_packing(phi_m)\n",
    "eta_f= viscosity_no_PP(eta_0,0.12,10)\n",
    "V_ax = Re*eta_f/(rho_f*i_d) \n",
    "gamma_w = (8*V_ax)*1.95/i_d\n",
    "\n",
    "\n",
    "def J_brownian(a, phi_w, phi_b):\n",
    "    numerator = gamma_w * (k_B ** 2) * (T ** 2)\n",
    "    denominator = (eta_f ** 2) * (a ** 2) * L\n",
    "    term = (numerator / denominator) ** (1/3)\n",
    "    J = 0.114 * term * (math.log((abs(phi_w / phi_b))))\n",
    "    return J\n",
    "\n",
    "# Function to calculate J for shear-induced diffusion\n",
    "def J_shear(a, phi_w, phi_b):\n",
    "    term = (a ** 4 / L) ** (1/3)\n",
    "    log_term = math.log(abs(phi_w / phi_b))\n",
    "    J = 0.078 * term * gamma_w * (log_term)\n",
    "    return J\n",
    "\n",
    "# Function to calculate J for inertial lift\n",
    "def J_inertial(a):\n",
    "    J = (0.036 * rho_p * (a ** 3) * (gamma_w ** 2)) / eta_f\n",
    "    return J\n",
    "#J solvent permeation flux (m/s)\n",
    "\n",
    "\n",
    "def get_protein_info(uniprot_code, pH):\n",
    "    Entrez.email = \"s230152@dtu.dk\"\n",
    "    handle = Entrez.esearch(db=\"protein\", term=uniprot_code, retmax=1)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "\n",
    "    protein_id = record[\"IdList\"][0]\n",
    "\n",
    "    handle = Entrez.efetch(db=\"protein\", id=protein_id, rettype=\"gb\", retmode=\"text\")\n",
    "    record = handle.read()\n",
    "    handle.close()\n",
    "\n",
    "    seq_record = SeqIO.read(StringIO(record), \"genbank\")\n",
    "    protein_sequence = seq_record.seq\n",
    "    protein = IP(protein_sequence)\n",
    "\n",
    "    iep = protein.pi()\n",
    "    net_charge = protein.charge_at_pH(pH)\n",
    "\n",
    "    return iep, net_charge\n",
    "uniprot_code = {a:uniprot_code for a,uniprot_code in zip([particle['name'] for particle in particles],['P0DOX5','P02768','P05814'])}\n",
    "net_charge = {}\n",
    "for particle in particles:\n",
    "    particle['iep'], particle['net_charge'] = get_protein_info(uniprot_code[particle['name']], pH)\n",
    "    net_charge[particle['name']] = particle['net_charge']\n",
    "# net_charge = {'10nm': 11.43, '180nm': -10.63, '300nm': -4.67} #ph 6.8\n",
    "# L_p =(porosity*(p_s)**2)/(8*eta_f*delta_membrane)\n",
    "L_p= 99/3600/1000/1000   \n",
    "s = (( 5*eta_f* delta_membrane * L_p) /porosity)**(1/2)\n",
    "k = (((permitivity*R*T)/(((F**2)*(2*I))))**(1/2))\n",
    "lambda_aph_dict={}\n",
    "for particle,charge in zip(particles,net_charge.values()):\n",
    "    z = charge\n",
    "    phi_b = particle['phi_b']\n",
    "    a = particle['radius']\n",
    "    lambda_aph = 1 - math.exp(-a/(2*s))\n",
    "    \n",
    "    delta_s = ((z)*e)/(4*math.pi*(a**2))\n",
    "    eff_a = a + (((4*(a**3)*(delta_s**2))/(permitivity*k_B*T))*0.2*k)\n",
    "    particle[\"radius\"]=eff_a\n",
    "    lambda_aph_dict[eff_a] = lambda_aph\n",
    "# print(lambda_aph_dict)\n",
    "target_species = particles[0]['radius']\n",
    "phi_w_dict={key:values for key, values in zip([particle['radius'] for particle in particles], phi_w_guess)}\n",
    "set_data = pd.DataFrame(columns=['name', 'radius', 'max_velocity', 'source'])\n",
    "\n",
    "\n",
    "def min_flux(Particles, phi_w_list):\n",
    "    \"\"\" have to put particles list with radius and phi_b,\n",
    "    phi_w_list with phi_w\n",
    "    results ai_target, J_flux and dataframe\"\"\"\n",
    "    \n",
    "    min_velocity = float('inf')\n",
    "    selected_particle_radius = None\n",
    "    velocities_list=[]\n",
    "\n",
    "    for particle, phi_w in zip(Particles, phi_w_list):\n",
    "        a = particle['radius']\n",
    "        phi_b = particle['phi_b']\n",
    "        \n",
    "        # Calculate velocities\n",
    "        brownian_velocity = J_brownian(a, phi_w, phi_b)\n",
    "        shear_velocity = J_shear(a, phi_w, phi_b)\n",
    "        inertial_velocity = J_inertial(a)\n",
    "        \n",
    "        # Find the maximum velocity\n",
    "        max_velocity = max(brownian_velocity, inertial_velocity, shear_velocity)\n",
    "        \n",
    "        # Determine the source of the maximum velocity\n",
    "        source = 'brownian' if max_velocity == brownian_velocity else 'inertial' if max_velocity == inertial_velocity else 'shear'\n",
    "        \n",
    "        # Update set_data by replacing previous row or adding a new one\n",
    "        if particle['name'] in set_data['name'].values:\n",
    "            set_data.loc[set_data['name'] == particle['name'], ['radius', 'max_velocity', 'source']] = [a, max_velocity, source]\n",
    "        else:\n",
    "            set_data.loc[len(set_data)] = [particle['name'], a, max_velocity, source]\n",
    "        # Store all velocities in the DataFrame\n",
    "        velocities_list.append({\n",
    "            'name': particle['name'],\n",
    "            'radius': a,\n",
    "            'brownian_velocity': brownian_velocity,\n",
    "            'shear_velocity': shear_velocity,\n",
    "            'inertial_velocity': inertial_velocity\n",
    "        })\n",
    "        velocities_df=pd.DataFrame(velocities_list)\n",
    "        # Check for the minimum velocity\n",
    "        if max_velocity < min_velocity:\n",
    "            min_velocity = max_velocity\n",
    "            selected_particle_radius = a\n",
    "\n",
    "    return selected_particle_radius, min_velocity, set_data,velocities_df\n",
    "\n",
    "# Initialize variables for particles and inertial-lift properties\n",
    "# ai_target, min_vel, dataf= min_flux(particles, phi_w_guess)\n",
    "\n",
    "# Function to calculate φ_w for each particle size\n",
    "def calculate_phi_w(Particles, a_target, min_velocity, data):\n",
    "    count = 0\n",
    "    # Dictionaries to store results\n",
    "    phi_w_J_dict = {}\n",
    "    phi_wjI_dict = {}\n",
    "    inertial_particles = []\n",
    "    \n",
    "    for particle in Particles:\n",
    "        a_particle = particle['radius']\n",
    "        phi_b_particle = particle['phi_b']\n",
    "        \n",
    "        if a_particle != a_target:\n",
    "            # Retrieve the velocity source from the data DataFrame\n",
    "            source = data.loc[data['radius'] == a_particle, 'source'].values[0]\n",
    "            \n",
    "            max_velocity = data.loc[data['radius'] == a_particle, 'max_velocity'].values[0]\n",
    "            if max_velocity >= 10 * min_velocity:\n",
    "                # Handle inertial particles\n",
    "                phi_wjI = 0\n",
    "                phi_wjI_dict[a_particle] = phi_wjI\n",
    "                phi_w_dict[a_particle] = phi_wjI\n",
    "                phi_w_J_dict[a_particle] = phi_wjI\n",
    "                inertial_particles.append((a_particle, phi_b_particle, max_velocity))\n",
    "            if source == \"inertial\":\n",
    "                count += 1\n",
    "            else:\n",
    "\n",
    "                    def objective_function(phi_w_particle):\n",
    "                        max_velocity = max(J_brownian(a_particle, phi_w_particle, phi_b_particle),J_shear(a_particle, phi_w_particle, phi_b_particle))\n",
    "                        return abs(max_velocity - min_velocity)\n",
    "               \n",
    "            #     # Minimize the objective function to find the optimal phi_w for the particle\n",
    "                    if a_particle == min(phi_w_dict.keys()):\n",
    "                        result = minimize_scalar(objective_function, bounds=(0, 0.74), method='bounded')\n",
    "                    else:\n",
    "                        result = minimize_scalar(objective_function, bounds=(0, 0.64), method='bounded')\n",
    "\n",
    "                    if result.success:\n",
    "                        phi_w_optimal = result.x\n",
    "                        phi_w_dict[a_particle] = phi_w_optimal\n",
    "                        phi_w_J_dict[a_particle] = phi_w_optimal\n",
    "                    else:\n",
    "                        print(f\"Optimization failed for particle radius {a_particle:.1e} m\")\n",
    "    # Handle inertial particles after processing all particles\n",
    "    if count == 1:\n",
    "        for a, phi_b, u_j in inertial_particles:\n",
    "            if phi_w_J_dict[a]!=0:\n",
    "                phi_wjI = phi_M - sum(phi_w_J_dict.values())\n",
    "                phi_wjI_dict[a] = phi_wjI\n",
    "                phi_w_dict[a] = phi_wjI\n",
    "    elif count > 1:\n",
    "        total_u_j_inv = sum((phi_b / u_j) for _, phi_b, u_j in inertial_particles)\n",
    "        phi_w_remaining = phi_M - sum(phi_w_J_dict.values())\n",
    "        phi_w_jI_sum = sum((phi_b / u_j) / total_u_j_inv * phi_w_remaining for _, phi_b, u_j in inertial_particles)\n",
    "        if abs(phi_M - (sum(phi_w_J_dict.values()) + phi_w_jI_sum)) > 1e-6:\n",
    "            print(\"Warning: φ_M and the sum of φ_w_j do not match closely enough.\")\n",
    "        \n",
    "        for a, phi_b, u_j in inertial_particles:\n",
    "            if phi_w_J_dict[a]!=0:\n",
    "                phi_wjI = (phi_b / u_j) / total_u_j_inv * phi_w_remaining\n",
    "                phi_wjI_dict[a] = phi_wjI\n",
    "                phi_w_dict[a] = phi_wjI\n",
    "\n",
    "    return phi_w_dict\n",
    "\n",
    "\n",
    "# Output the updated dictionary\n",
    "#print(f\"Updated phi_w_dict: {phi_w_dict}\")\n",
    "def packing_constraints(Particles, phi_w_list):\n",
    "    ai_target, min_vel, dataf,vel= min_flux(Particles, phi_w_list)\n",
    "    \n",
    "    phi_w_updated=calculate_phi_w(Particles, ai_target, min_vel, dataf)\n",
    "    tolerance = 1e-6  # Set a tolerance for convergence\n",
    "    max_iterations = 100\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        remaining_phiw_j = {a: phi_w for a, phi_w in phi_w_updated.items() if a != min(phi_w_updated.keys())}\n",
    "        phi_w_i = phi_w_updated[ai_target] # Wall concentration of the target particle\n",
    "        # Check if packing constraints are satisfied\n",
    "        if (phi_M >= sum(phi_w_updated.values())) and (sum(remaining_phiw_j.values()) <= 0.68):\n",
    "            # print(f\"Iteration {i}: Packing constraints are met.\")\n",
    "            return phi_w_updated,   min_vel, ai_target, dataf\n",
    "        phi_w_previous = phi_w_updated.copy()\n",
    "        # Update phi_w for the target particle\n",
    "        phi_w_i_corrected = phi_M * (phi_w_i / sum(phi_w_updated.values()))\n",
    "        \n",
    "        phi_w_updated[ai_target] = phi_w_i_corrected\n",
    "        phi_w_j = {a: phi_w for a, phi_w in remaining_phiw_j.items() if a != ai_target}\n",
    "        if (sum(remaining_phiw_j.values()) <= 0.68)==False and ai_target in remaining_phiw_j.keys() and i>15:\n",
    "            phi_w_updated[ai_target]=0.68 *(phi_w_updated[ai_target]/(sum(remaining_phiw_j.values())))\n",
    "            # print(phi_w_updated[ai_target])\n",
    "        if (phi_w_updated[min(phi_w_updated.keys())] <= 0.74 * (1 - sum(remaining_phiw_j.values()))) == False and ai_target==min(phi_w_updated.keys())  and i>15:\n",
    "            phi_w_updated[min(phi_w_updated.keys()) ]= 0.74 * (1 - sum(remaining_phiw_j.values()))\n",
    "        # Store the previous values of phi_w for comparison\n",
    "        \n",
    "        # print(phi_w_i_corrected)\n",
    "        # Recalculate the flux and phi_w_j values after updating\n",
    "        _, min_vel, dataf,vel= min_flux(particles, phi_w_updated.values())\n",
    "        phi_w_updated=calculate_phi_w(particles, ai_target, min_vel, dataf)\n",
    "\n",
    "        # Check for the change in phi_w values between iterations\n",
    "        phi_w_diff = sum(abs(phi_w_updated[a] - phi_w_previous[a]) for a in phi_w_updated)\n",
    "\n",
    "        # If the change in phi_w values is smaller than the tolerance, stop the iteration\n",
    "        # if phi_w_diff < tolerance:\n",
    "        #     print(f\"Iteration {i}: Will not converger further.\")\n",
    "        #     return phi_w_updated,   min_vel, ai_target, dataf\n",
    "    # If the loop completes without finding a solution\n",
    "    # print(\"Warning: No solution found within the iteration limit.\")\n",
    "\n",
    "  \n",
    "    return phi_w_updated, min_vel, ai_target, dataf\n",
    "\n",
    "def J_flux_calculation(Particles, phi_w_list):\n",
    "    # Unpack the results from packing_constraints\n",
    "    phi_w_updated, J_flux, ai_target, dataf = packing_constraints(Particles, phi_w_list)\n",
    "    # print(phi_w_updated)\n",
    "    \n",
    "    # Initialize J_pi with J_flux values from packing constraints for all particles\n",
    "    J_pi = {a: J_flux for a in phi_w_updated.keys()}\n",
    "    \n",
    "    phi_w_dict_T = {}\n",
    "    phi_w_dict_R = {}\n",
    "    # Separate phi_w values into two dictionaries based on particle size comparison with p_s/2\n",
    "    for (a, phi_w) in phi_w_updated.items():\n",
    "        \n",
    "        if a <= p_s / 2:\n",
    "            phi_w_dict_T[a] = phi_w\n",
    "            # print(phi_w_dict_T)\n",
    "        else:\n",
    "            phi_w_dict_R[a] = phi_w\n",
    "            # print(phi_w_dict_R)\n",
    "\n",
    "    # Update phi_w for particles in phi_w_dict_T based on ratio of min(phi_w_dict_R.keys()) / a\n",
    "    for (a, phi_w) in phi_w_dict_T.items():\n",
    "        if (min(phi_w_dict_R.keys()) / a )< 10:\n",
    "            phi_w_updated[a] = 0.68 * (1 - sum(phi_w_dict_R.values()))\n",
    "        else:\n",
    "            phi_w_updated[a] = 0.74 * (1 - sum(phi_w_dict_R.values()))\n",
    "    \n",
    "    # Calculate J_pi only for particles in phi_w_dict_T\n",
    "    for a , particle in zip(phi_w_dict_T.keys(), Particles):\n",
    "\n",
    "        phi_b = particle['phi_b']\n",
    "        \n",
    "        # Calculate velocities\n",
    "        brownian_velocity = J_brownian(a, phi_w_updated[a], phi_b)\n",
    "        shear_velocity = J_shear(a, phi_w_updated[a], phi_b)\n",
    "        inertial_velocity = J_inertial(a)\n",
    "        \n",
    "        # Update J_pi with the maximum velocity for particles in phi_w_dict_T\n",
    "        max_velocity = max(brownian_velocity, inertial_velocity, shear_velocity)\n",
    "        J_pi[a] = max_velocity\n",
    "\n",
    "    return J_pi, phi_w_updated, J_flux, ai_target, dataf\n",
    "\n",
    "# print(J_flux_calculation(particles, phi_w_guess))\n",
    "#mass-transfer coefficient calculated from equation  1#step 10\n",
    "\n",
    "\n",
    "def sieving_parameters(Particles, phi_w_list):\n",
    "    \n",
    "    J_pi,phi_w_updated, J_flux, ai_target, dataf = J_flux_calculation(Particles, phi_w_list)\n",
    "   \n",
    "    S_oi_dep = {a: (1-(J_actual / J_pi[a])) for a in phi_w_updated.keys()}\n",
    "    S_oi_membrane = {a: 0 for a in phi_w_updated.keys()}\n",
    "    S_oi = {a: 0 for a in phi_w_updated.keys()}\n",
    "    for particle,phi_w in zip(Particles,phi_w_updated.values()):\n",
    "        phi_b = particle['phi_b']\n",
    "        a = particle['radius']\n",
    "        \n",
    "        lambda_aph =lambda_aph_dict[a]\n",
    "        # print(f\"lambda_aph: {lambda_aph}\")\n",
    "        diffusion_coeff = (k_B * T) / (6 * math.pi * eta_f * a)\n",
    "        mass_transfer_k = J_pi[a]/math.log(abs(phi_w/phi_b))\n",
    "      \n",
    "        Sieving_coeff_int = ((1 - lambda_aph) ** 2) * (2 - ((1 - lambda_aph) ** 2)) * math.exp(-0.7146 * (lambda_aph ** 2))\n",
    "        # print(f\"Initial Sieving coefficient: {Sieving_coeff_int}\")\n",
    "        phi_e_K_d = (1 - lambda_aph) ** (9 / 2)\n",
    "        # print(f\"phi_e_K_d: {phi_e_K_d}\")\n",
    "        Peclet_m = ((J_actual * (delta_membrane)) / diffusion_coeff) * (Sieving_coeff_int / (porosity * phi_e_K_d))\n",
    "        # print(f\"Peclet_m: {Peclet_m}\")\n",
    "        # print  (f\"Peclet_m: {Peclet_m}\")\n",
    "        if Peclet_m >709:\n",
    "            Sieving_coeff_act = Sieving_coeff_int\n",
    "        else:\n",
    "            Sieving_coeff_act = (Sieving_coeff_int * math.exp(Peclet_m)) / ((Sieving_coeff_int + math.exp(Peclet_m)) - 1)\n",
    "            \n",
    "        # print(f\"Actual Sieving coefficient: {Sieving_coeff_act}\")\n",
    "        Sieving_coeff_obs = Sieving_coeff_act / ((1 - Sieving_coeff_act) * math.exp(-J_actual / mass_transfer_k) + Sieving_coeff_act)\n",
    "        # print(f\"Sieving coefficient: {Sieving_coeff_obs}\")\n",
    "        S_oi_membrane[a] = Sieving_coeff_obs\n",
    "        S_oi[a] = S_oi_dep[a] * S_oi_membrane[a]\n",
    "    # print(S_oi_membrane)\n",
    "    \n",
    "    # yields = 1 - math.exp(-4 * (Sieving_coeff_obs))\n",
    "    # print(f\"Yields: {yields}\")\n",
    "            \n",
    "    return J_flux, S_oi, phi_w_updated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_actual = 2.777778e-07: Yield reached 95% in 176028.80 seconds.\n",
      "Iteration with J_actual = 7.227153e-07 completed in 413.13 seconds.\n",
      "J_actual = 7.227153e-07: Yield reached 95% in 71753.59 seconds.\n",
      "Iteration with J_actual = 1.167653e-06 completed in 483.73 seconds.\n",
      "J_actual = 1.167653e-06: Yield reached 95% in 46942.35 seconds.\n",
      "Iteration with J_actual = 1.612590e-06 completed in 476.42 seconds.\n",
      "J_actual = 1.612590e-06: Yield reached 95% in 35781.79 seconds.\n",
      "Iteration with J_actual = 2.057528e-06 completed in 453.03 seconds.\n",
      "J_actual = 2.057528e-06: Yield reached 95% in 29721.49 seconds.\n",
      "Iteration with J_actual = 2.502465e-06 completed in 448.84 seconds.\n",
      "J_actual = 2.502465e-06: Yield reached 95% in 25861.29 seconds.\n",
      "Iteration with J_actual = 2.947403e-06 completed in 507.91 seconds.\n",
      "J_actual = 2.947403e-06: Yield reached 95% in 23341.17 seconds.\n",
      "Iteration with J_actual = 3.392340e-06 completed in 485.22 seconds.\n",
      "J_actual = 3.392340e-06: Yield reached 95% in 21791.09 seconds.\n",
      "Iteration with J_actual = 3.837278e-06 completed in 502.90 seconds.\n",
      "J_actual = 3.837278e-06: Yield reached 95% in 20771.04 seconds.\n",
      "Iteration with J_actual = 4.282215e-06 completed in 471.33 seconds.\n",
      "J_actual = 4.282215e-06: Yield reached 95% in 20241.01 seconds.\n",
      "Iteration with J_actual = 4.727153e-06 completed in 483.10 seconds.\n",
      "Simulation completed. Results saved.\n"
     ]
    }
   ],
   "source": [
    "# Discrete system\n",
    "import copy  # For deep copying\n",
    "\n",
    "# Save the initial values of particles and phi_w_dict\n",
    "particles_initial = copy.deepcopy(particles)\n",
    "phi_w_dict_initial = copy.deepcopy(phi_w_dict)\n",
    "phi_b1_initial = np.array([p['phi_b'] for p in particles])  # Initial retentate concentrations\n",
    "phi_b2_initial = np.zeros(len(particles))  # Initial permeate concentrations\n",
    "J_actual = 1 / 3600 / 1000\n",
    "total_time = 200000\n",
    "V_2 = 500e-6  # Permeate volume (m³)\n",
    "V_1 = 50e-6   # Feed volume (m³)\n",
    "J_PD = 4.4493750873539455e-06 \n",
    "\n",
    "# Initializing storage for sieving coefficients and cumulative yields\n",
    "\n",
    "# Function to calculate concentration dynamics\n",
    "def concentration_dynamics(t, y):\n",
    "    # Split retentate and permeate concentrations\n",
    "    phi_b1 = y[:len(particles)]  # Retentate concentrations\n",
    "    phi_b2 = y[len(particles):]  # Permeate concentrations\n",
    "\n",
    "    # Update particle data\n",
    "    for i, p in enumerate(particles):\n",
    "        p['phi_b'] = phi_b1[i]\n",
    "\n",
    "    # Calculate system variables\n",
    "    eta_f = viscosity_no_PP(eta_0, sum(p['phi_b'] for p in particles), 10)\n",
    "    V_ax = Re * eta_f / (rho_f * i_d)\n",
    "    gamma_w = (8 * V_ax) * 1.95 / i_d\n",
    "\n",
    "    # Recalculate sieving coefficients and other parameters\n",
    "    J_flux, S_oi_dict, phi_w_updated = sieving_parameters(particles, phi_w_dict.values())\n",
    "    S_oi = np.array([S_oi_dict[p['radius']] for p in particles])  # Extract sieving coefficients\n",
    "\n",
    "    # Calculate derivatives for retentate and permeate\n",
    "    dphi_b1_dt = np.zeros(len(particles))\n",
    "    dphi_b2_dt = np.zeros(len(particles))\n",
    "\n",
    "    for i, p in enumerate(particles):\n",
    "        # Retentate dynamics\n",
    "        dphi_b1_dt[i] = - (A * J_actual * (S_oi[i]) * phi_b1[i]) / V_1\n",
    "        # Permeate dynamics\n",
    "        dphi_b2_dt[i] = (A * J_actual * S_oi[i] * phi_b1[i]) / V_2\n",
    "\n",
    "    # Combine into a single array\n",
    "    return np.concatenate([dphi_b1_dt, dphi_b2_dt])\n",
    "\n",
    "# Initial conditions\n",
    "y0 = np.concatenate([phi_b1_initial, phi_b2_initial])  # Initial retentate and permeate concentrations\n",
    "\n",
    "def simulate_process(J_actual):\n",
    "    # Solve the system of ODEs\n",
    "    solution = solve_ivp(\n",
    "        concentration_dynamics,\n",
    "        t_span=(0, total_time),\n",
    "        y0=y0,\n",
    "        method='RK45',\n",
    "        t_eval=np.linspace(0, total_time, 20000)\n",
    "    )\n",
    "\n",
    "    # Extract results\n",
    "    time_points = solution.t\n",
    "    phi_b1_solution = solution.y[:len(particles), :].T  # Retentate concentrations over time\n",
    "    phi_b2_solution = solution.y[len(particles):, :].T  # Permeate concentrations over time\n",
    "\n",
    "    # Calculate cumulative yield as (phi_b2 * V_2) / (phi_b1_initial * V_1)\n",
    "    yield_fraction = (phi_b2_solution * V_2) / (phi_b1_initial * V_1)\n",
    "\n",
    "    # Find when yield reaches 95%\n",
    "    stop_index = np.argmax(yield_fraction[:, 0] >= 0.95)  # Stop at first occurrence of 95%\n",
    "    if yield_fraction[stop_index, 0] < 0.95:\n",
    "        stop_index = len(time_points) - 1  # No 95% yield reached\n",
    "\n",
    "    time_reached_95 = time_points[stop_index] if stop_index < len(time_points) else None\n",
    "\n",
    "    # Get the sieving coefficients for each particle\n",
    "    sieving_coefficients = np.zeros((len(time_points), len(particles)))\n",
    "    for t_idx in range(len(time_points)):\n",
    "        phi_b1_t = phi_b1_solution[t_idx, :]\n",
    "        for i, p in enumerate(particles):\n",
    "            p['phi_b'] = phi_b1_t[i]\n",
    "        J_flux, S_oi_dict,phi_w_updated = sieving_parameters(particles, phi_w_dict.values())\n",
    "        sieving_coefficients[t_idx, :] = [S_oi_dict[p['radius']] for p in particles]\n",
    "\n",
    "    # Store results\n",
    "    results_df = pd.DataFrame({'Time (s)': time_points[:stop_index + 1]})\n",
    "    for i, p in enumerate(particles):\n",
    "        results_df[f'{p[\"name\"]}_retentate'] = phi_b1_solution[:stop_index + 1, i]\n",
    "        results_df[f'{p[\"name\"]}_permeate'] = phi_b2_solution[:stop_index + 1, i]\n",
    "        results_df[f'{p[\"name\"]}_cumulative_yield'] = yield_fraction[:stop_index + 1, i]\n",
    "        results_df[f'{p[\"name\"]}_sieving_coefficient'] = sieving_coefficients[:stop_index + 1, i]\n",
    "\n",
    "    return results_df, time_reached_95\n",
    "\n",
    "# Simulation loop\n",
    "\n",
    "\n",
    "# Simulation loop\n",
    "J_increment = J_PD / 10  # Define increment for J_actual\n",
    "all_iterations_results = []\n",
    "iteration_summary = []\n",
    "\n",
    "import time  # To measure simulation duration\n",
    "\n",
    "# Modify the simulation loop\n",
    "J_increment = J_PD / 10  # Define increment for J_actual\n",
    "all_iterations_results = []\n",
    "iteration_summary = []\n",
    "\n",
    "while J_actual <= J_PD:\n",
    "    # Start timing the iteration\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Reset particles and phi_w_dict to their initial values\n",
    "    particles = copy.deepcopy(particles_initial)\n",
    "    phi_w_dict = copy.deepcopy(phi_w_dict_initial)\n",
    "\n",
    "    try:\n",
    "        # Run the simulation\n",
    "        results_df, time_to_95 = simulate_process(J_actual)\n",
    "\n",
    "        # If yield reaches 95%, store results\n",
    "        if time_to_95 is not None:\n",
    "            print(f\"J_actual = {J_actual:.6e}: Yield reached 95% in {time_to_95:.2f} seconds.\")\n",
    "            iteration_summary.append({\n",
    "                'J_actual': J_actual,\n",
    "                'Time_to_95%': time_to_95\n",
    "            })\n",
    "            all_iterations_results.append(results_df)\n",
    "\n",
    "            # Save results for this iteration with J_actual in the filename\n",
    "            filename = f'dynamic_simulation_J_actual_{J_actual:.6e}.csv'\n",
    "            results_df.to_csv(filename, index=False)\n",
    "\n",
    "        else:\n",
    "            print(f\"J_actual = {J_actual:.6e}: Yield did not reach 95%. Moving to next J_actual.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during simulation for J_actual = {J_actual:.6e}: {e}\")\n",
    "\n",
    "    # Increment J_actual for the next iteration\n",
    "    J_actual += J_increment\n",
    "\n",
    "    # End timing and print the duration\n",
    "    end_time = time.time()\n",
    "    print(f\"Iteration with J_actual = {J_actual:.6e} completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Save all results\n",
    "if all_iterations_results:\n",
    "    final_results_df = pd.concat(all_iterations_results, ignore_index=True)\n",
    "    final_results_df.to_csv('dynamic_simulation_results_with_correct_yield.csv', index=False)\n",
    "\n",
    "if iteration_summary:\n",
    "    summary_df = pd.DataFrame(iteration_summary)\n",
    "    summary_df.to_csv('iteration_summary.csv', index=False)\n",
    "\n",
    "print(\"Simulation completed. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12348.877787835576"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "620*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337.35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20241/60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
