{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize_scalar\n",
    "import numpy as np\n",
    "from Bio.SeqUtils.IsoelectricPoint import IsoelectricPoint as IP\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "import copy\n",
    "import time\n",
    "from scipy.integrate import solve_ivp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping J_actual = 6.98 due to zero columns.\n",
      "Skipping J_actual = 7.47 due to zero columns.\n",
      "Skipping J_actual = 11.58 due to zero columns.\n",
      "Skipping J_actual = 8.78 due to zero columns.\n",
      "Finished iteration for pH=5, X=8, I=1\n",
      "Skipping J_actual = 9.56 due to zero columns.\n",
      "Skipping J_actual = 8.67 due to time limit.\n",
      "Finished iteration for pH=6, X=8, I=1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 555\u001b[0m\n\u001b[1;32m    551\u001b[0m phi_w_dict \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(phi_w_dict_initial)\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# Run the simulation\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m     results_df, sieving_df\u001b[38;5;241m=\u001b[39m \u001b[43msimulate_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ_actual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;66;03m# Check if the first 4 columns contain zero\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     column_subset \u001b[38;5;241m=\u001b[39m sieving_df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m5\u001b[39m]\n",
      "Cell \u001b[0;32mIn[20], line 486\u001b[0m, in \u001b[0;36msimulate_process\u001b[0;34m(J_actual)\u001b[0m\n\u001b[1;32m    484\u001b[0m J_flux_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# Solve the system of ODEs\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43msolve_ivp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcentration_dynamics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRK23\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdiavolumes_event\u001b[49m\u001b[43m,\u001b[49m\u001b[43myield_event\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Add events to stop simulation\u001b[39;49;00m\n\u001b[1;32m    496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# Extract results\u001b[39;00m\n\u001b[1;32m    500\u001b[0m time_points \u001b[38;5;241m=\u001b[39m solution\u001b[38;5;241m.\u001b[39mt\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/ivp.py:655\u001b[0m, in \u001b[0;36msolve_ivp\u001b[0;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[1;32m    653\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    658\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/base.py:197\u001b[0m, in \u001b[0;36mOdeSolver.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt\n\u001b[0;32m--> 197\u001b[0m     success, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/rk.py:144\u001b[0m, in \u001b[0;36mRungeKutta._step_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m h \u001b[38;5;241m=\u001b[39m t_new \u001b[38;5;241m-\u001b[39m t\n\u001b[1;32m    142\u001b[0m h_abs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(h)\n\u001b[0;32m--> 144\u001b[0m y_new, f_new \u001b[38;5;241m=\u001b[39m \u001b[43mrk_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m scale \u001b[38;5;241m=\u001b[39m atol \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(np\u001b[38;5;241m.\u001b[39mabs(y), np\u001b[38;5;241m.\u001b[39mabs(y_new)) \u001b[38;5;241m*\u001b[39m rtol\n\u001b[1;32m    147\u001b[0m error_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_error_norm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK, h, scale)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/rk.py:64\u001b[0m, in \u001b[0;36mrk_step\u001b[0;34m(fun, t, y, f, h, A, B, C, K)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, (a, c) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(A[\u001b[38;5;241m1\u001b[39m:], C[\u001b[38;5;241m1\u001b[39m:]), start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     63\u001b[0m     dy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(K[:s]\u001b[38;5;241m.\u001b[39mT, a[:s]) \u001b[38;5;241m*\u001b[39m h\n\u001b[0;32m---> 64\u001b[0m     K[s] \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m y_new \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m h \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(K[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT, B)\n\u001b[1;32m     67\u001b[0m f_new \u001b[38;5;241m=\u001b[39m fun(t \u001b[38;5;241m+\u001b[39m h, y_new)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/base.py:154\u001b[0m, in \u001b[0;36mOdeSolver.__init__.<locals>.fun\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m(t, y):\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/integrate/_ivp/base.py:23\u001b[0m, in \u001b[0;36mcheck_arguments.<locals>.fun_wrapped\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(t, y):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "Cell \u001b[0;32mIn[20], line 430\u001b[0m, in \u001b[0;36mconcentration_dynamics\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m    427\u001b[0m     gamma_w \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m Q)  \u001b[38;5;241m/\u001b[39m ((h\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mw)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# Recalculate sieving coefficients and other parameters\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     J_flux, S_oi_dict,_ \u001b[38;5;241m=\u001b[39m \u001b[43msieving_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_w_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgamma_w\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     J_flux_list\u001b[38;5;241m.\u001b[39mappend(J_flux)\n\u001b[1;32m    433\u001b[0m     S_oi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([S_oi_dict\u001b[38;5;241m.\u001b[39mget(p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradius\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m particles]) \u001b[38;5;66;03m# Extract sieving coefficients\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 352\u001b[0m, in \u001b[0;36msieving_parameters\u001b[0;34m(Particles, phi_w_list, gamma_w)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msieving_parameters\u001b[39m(Particles, phi_w_list,gamma_w):\n\u001b[0;32m--> 352\u001b[0m     J_pi,phi_w_dict, J_flux \u001b[38;5;241m=\u001b[39m \u001b[43mJ_flux_calculation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_w_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgamma_w\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     S_oi_dep \u001b[38;5;241m=\u001b[39m {a: (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m(J_actual \u001b[38;5;241m/\u001b[39m J_pi[a])) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m phi_w_dict\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[1;32m    354\u001b[0m     S_oi_membrane \u001b[38;5;241m=\u001b[39m {a: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m phi_w_dict\u001b[38;5;241m.\u001b[39mkeys()}\n",
      "Cell \u001b[0;32mIn[20], line 301\u001b[0m, in \u001b[0;36mJ_flux_calculation\u001b[0;34m(Particles, phi_w_list, gamma_w)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mJ_flux_calculation\u001b[39m(Particles, phi_w_list,gamma_w):\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Unpack the results from packing_constraints\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     phi_w_dict, J_flux \u001b[38;5;241m=\u001b[39m \u001b[43mpacking_constraints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_w_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgamma_w\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# print(phi_w_dict)\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     phi_w_dict_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(phi_w_dict)\n",
      "Cell \u001b[0;32mIn[20], line 242\u001b[0m, in \u001b[0;36mpacking_constraints\u001b[0;34m(Particles, phi_w_list, gamma_w)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Update phi_w for the target particle\u001b[39;00m\n\u001b[1;32m    240\u001b[0m phi_w_dict[ai_target] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.9064\u001b[39m) \u001b[38;5;241m*\u001b[39m (phi_w_dict[ai_target] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(phi_w_dict\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m--> 242\u001b[0m ai_target, min_vel, dataf\u001b[38;5;241m=\u001b[39m \u001b[43mmin_flux\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_w_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgamma_w\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# min_vel = dataf.loc[dataf['radius'] == ai_target, 'max_velocity'].values[0]\u001b[39;00m\n\u001b[1;32m    244\u001b[0m phi_w_dict\u001b[38;5;241m=\u001b[39mcalculate_phi_w(particles, ai_target, min_vel, dataf,gamma_w)\n",
      "Cell \u001b[0;32mIn[20], line 167\u001b[0m, in \u001b[0;36mmin_flux\u001b[0;34m(Particles, phi_w_list, gamma_w)\u001b[0m\n\u001b[1;32m    165\u001b[0m     set_data\u001b[38;5;241m.\u001b[39mloc[set_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m particle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradius\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_velocity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m [a, max_velocity, source]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mset_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mset_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [particle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], a, max_velocity, source]\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phi_w \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Check for the minimum velocity\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_velocity \u001b[38;5;241m<\u001b[39m min_velocity:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:1932\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m-> 1932\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexing.py:2328\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[1;32m   2329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_maybe_update_cacher(clear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:10572\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m  10569\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m  10570\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m, other]\n\u001b[0;32m> 10572\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10576\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10577\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/concat.py:149\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m             nb \u001b[38;5;241m=\u001b[39m _concat_homogeneous_fastpath(mgrs_indexers, shape, first_dtype)\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m BlockManager((nb,), axes)\n\u001b[0;32m--> 149\u001b[0m mgrs \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_reindex_columns_na_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    152\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m mgrs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/concat.py:219\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[0;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[1;32m    214\u001b[0m new_mgrs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mgr, indexers \u001b[38;5;129;01min\u001b[39;00m mgrs_indexers:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# For axis=0 (i.e. columns) we use_na_proxy and only_slice, so this\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m#  is a cheap reindexing.\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, indexer \u001b[38;5;129;01min\u001b[39;00m \u001b[43mindexers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    220\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    221\u001b[0m             axes[i],\n\u001b[1;32m    222\u001b[0m             indexers[i],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m             use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# only relevant for i==0\u001b[39;00m\n\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for X in range(8,9,2):\n",
    "    for I in [1,21]:\n",
    "            for pH in range(5,10,1):    \n",
    "\n",
    "                L= 0.05 # module length in meters\n",
    "                n_f = 9 #number of fibers\n",
    "                A = 0.0030 #m2\n",
    "                h = 0.4e-3 #m\n",
    "                w = 7e-3 #m\n",
    "\n",
    "                delta_membrane = 0.125e-3 #m\n",
    "                p_s = 0.2e-6 #pore size in meters\n",
    "                T = 277.15 #K\n",
    "                R = 8.314 #J/mol/K\n",
    "                F = 96485 #C/mol\n",
    "                e = 1.60217662e-19 #C\n",
    "                porosity = 0.70\n",
    "                # X = np.random.uniform(1, 10)\n",
    "                # pH =np.random.uniform(5, 10)\n",
    "\n",
    "                # I = np.random.uniform(0.001,180) #ionic strength mM\n",
    "                permitivity = 6.375e-10 #permitivity of the medium C^2(J.m)^-1\n",
    "                # gamma_w = 32400#shear rate s-1\n",
    "                phi_m = 0.64\n",
    "                eta_0 = 0.001#Pa.second viscosity of \n",
    "                rho_p = 1400 #kg/m3 density of the particles\n",
    "                rho_f = 1000 #kg/m3 density of the fluid\n",
    "                k_B = 1.38064852e-23 #J/mol/K Boltzmann constant\n",
    "\n",
    "\n",
    "\n",
    "                # Particle sizes (in meters)\n",
    "                particles = [\n",
    "                    {'name': '5nm', 'radius': 5e-9, 'phi_b': 7.81e-05*X},\n",
    "                    {'name': '40nm', 'radius': 40e-9, 'phi_b': 0.00012496*X},\n",
    "                    {'name': '70nm', 'radius': 70e-9, 'phi_b': 0.000461*0.710*X},\n",
    "                    {'name': '120nm', 'radius': 120e-9, 'phi_b': 0.000426*0.710*X},\n",
    "                    {'name': '190nm', 'radius': 190e-9, 'phi_b': 0.000220*0.710*X},\n",
    "                    {'name': '300nm', 'radius': 300e-9, 'phi_b': 0.000176*0.710*X},\n",
    "                    {'name': '700nm', 'radius': 700e-9, 'phi_b': 0.000154*0.710*X},\n",
    "                    {'name': '2500nm', 'radius': 2500e-9, 'phi_b': 0.000154*0.710*X},\n",
    "                ]\n",
    "\n",
    "                phi_bulk = sum(particles[i]['phi_b'] for i in range(len(particles)))\n",
    "\n",
    "                phi_w_guess = [0.64] * len(particles)\n",
    "\n",
    "                def viscosity_no_PP(eta_0,phi_b,k1):\n",
    "                    \"\"\"eta_0 - viscosity of the dispersion medium\n",
    "                    phi - volume in parts occupied by the dispersed solid\n",
    "                    k1 = shape factor\"\"\"\n",
    "                    \n",
    "                    eta_phi = eta_0*(1+(5/2)*phi_b+k1*(phi_b**2))\n",
    "                    return eta_phi\n",
    "                \n",
    "\n",
    "                def max_agg_packing (phi_m):\n",
    "                    phi_Max=phi_m+phi_m*(1-phi_m)+0.74*(1- (phi_m+ phi_m*(1-phi_m)))\n",
    "                    return phi_Max\n",
    "                phi_M = max_agg_packing(phi_m)\n",
    "\n",
    "                eta_f = viscosity_no_PP(eta_0, sum(particle['phi_b'] for particle in particles), 10)\n",
    "\n",
    "\n",
    "                def J_brownian(a, phi_w, phi_b,gamma_w):\n",
    "                    numerator = gamma_w * (k_B ** 2) * (T ** 2)\n",
    "                    denominator = (eta_f ** 2) * (a ** 2) * L\n",
    "                    term = (numerator / denominator) ** (1/3)\n",
    "                    if phi_w == 0:\n",
    "                        J=0\n",
    "                    else:\n",
    "                        J = 0.114 * term * (math.log((abs(phi_w / phi_b))))\n",
    "                    return J\n",
    "\n",
    "                # Function to calculate J for shear-induced diffusion\n",
    "                def J_shear(a, phi_w, phi_b,gamma_w):\n",
    "                    term = (a ** 4 / L) ** (1/3)\n",
    "                    log_term = (abs(phi_w / phi_b))\n",
    "                    if phi_w == 0:\n",
    "                            J=0\n",
    "                    elif phi_bulk <0.1:\n",
    "                            J = 0.126 * term * gamma_w * (log_term)**(1/3)\n",
    "                    else:\n",
    "                    \n",
    "                        J = 0.078 * term * gamma_w * abs(math.log(log_term))\n",
    "\n",
    "                    return J\n",
    "\n",
    "                #J solvent permeation flux (m/s)\n",
    "\n",
    "\n",
    "                def get_protein_info(uniprot_code, pH):\n",
    "                    Entrez.email = \"s230152@dtu.dk\"\n",
    "                    handle = Entrez.esearch(db=\"protein\", term=uniprot_code, retmax=1)\n",
    "                    record = Entrez.read(handle)\n",
    "                    handle.close()\n",
    "\n",
    "                    protein_id = record[\"IdList\"][0]\n",
    "\n",
    "                    handle = Entrez.efetch(db=\"protein\", id=protein_id, rettype=\"gb\", retmode=\"text\")\n",
    "                    record = handle.read()\n",
    "                    handle.close()\n",
    "\n",
    "                    seq_record = SeqIO.read(StringIO(record), \"genbank\")\n",
    "                    protein_sequence = seq_record.seq\n",
    "                    protein = IP(protein_sequence)\n",
    "\n",
    "                    iep = protein.pi()\n",
    "                    net_charge = protein.charge_at_pH(pH)\n",
    "\n",
    "                    return iep, net_charge\n",
    "                uniprot_code = {a:uniprot_code for a,uniprot_code in zip([particle['name'] for particle in particles],['P42212','P0A910','P0A7K6','P0AED0','P0A825','P0AD68','P0A9A6','P0A940'])}\n",
    "                net_charge = {}\n",
    "                # \n",
    "                for particle in particles:\n",
    "                    _, net_charge[particle['name']]  = get_protein_info(uniprot_code[particle['name']], pH)\n",
    "\n",
    "\n",
    "                L_p= 55/3600/1000/1000   \n",
    "                s = (( 5*eta_f* delta_membrane * L_p) /porosity)**(1/2)\n",
    "                k = (((permitivity*R*T)/(((F**2)*(2*I))))**(1/2))\n",
    "                lambda_aph_dict={}\n",
    "                for particle,charge in zip(particles,net_charge.values()):\n",
    "                        z = charge\n",
    "                        phi_b = particle['phi_b']\n",
    "                        a = particle['radius']\n",
    "                        lambda_aph = 1 - math.exp(-a/(2*s))\n",
    "                        delta_s = ((z)*e)/(4*math.pi*(a**2))\n",
    "                        eff_a = a + (((4*(a**3)*(delta_s**2))/(permitivity*k_B*T))*0.2*k)\n",
    "                        particle[\"radius\"]=eff_a\n",
    "                        lambda_aph_dict[eff_a] = lambda_aph\n",
    "\n",
    "                phi_w_dict={key:values for key, values in zip([particle['radius'] for particle in particles], phi_w_guess)}\n",
    "                particles_copy = copy.deepcopy(particles)\n",
    "\n",
    "\n",
    "                def min_flux(Particles, phi_w_list,gamma_w):\n",
    "                    \"\"\" have to put particles list with radius and phi_b,\n",
    "                    phi_w_list with phi_w\n",
    "                    results ai_target, J_flux and dataframe\"\"\"\n",
    "                    set_data = pd.DataFrame(columns=['name', 'radius', 'max_velocity', 'source'])\n",
    "                    # velocities_list = []\n",
    "                    min_velocity = float('inf')\n",
    "                    selected_particle_radius = None\n",
    "\n",
    "                    for particle, phi_w in zip(Particles, phi_w_list):\n",
    "                        \n",
    "                            a = particle['radius']\n",
    "                            phi_b = particle['phi_b']\n",
    "                            \n",
    "                            \n",
    "                            # Calculate velocities\n",
    "                            brownian_velocity = J_brownian(a, phi_w, phi_b,gamma_w)\n",
    "                            shear_velocity = J_shear(a, phi_w, phi_b,gamma_w)\n",
    "                        \n",
    "                            \n",
    "                            # Find the maximum velocity\n",
    "                            max_velocity = max(brownian_velocity,  shear_velocity)\n",
    "                            \n",
    "                            # Determine the source of the maximum velocity\n",
    "                            source = 'brownian' if max_velocity == brownian_velocity  else 'shear'\n",
    "                            \n",
    "                            # Update set_data by replacing previous row or adding a new one\n",
    "                            if particle['name'] in set_data['name'].values:\n",
    "                                set_data.loc[set_data['name'] == particle['name'], ['radius', 'max_velocity', 'source']] = [a, max_velocity, source]\n",
    "                            else:\n",
    "                                set_data.loc[len(set_data)] = [particle['name'], a, max_velocity, source]\n",
    "                        \n",
    "                        \n",
    "                            if phi_w !=0:\n",
    "                            # Check for the minimum velocity\n",
    "                                if max_velocity < min_velocity:\n",
    "                                    min_velocity = max_velocity\n",
    "                                    selected_particle_radius = a\n",
    "                            \n",
    "\n",
    "                    return selected_particle_radius, min_velocity, set_data\n",
    "\n",
    "                # Function to calculate Ï†_w for each particle size\n",
    "                def calculate_phi_w(Particles, a_target, min_velocity, data,gamma_w):\n",
    "                \n",
    "                    for particle in Particles:\n",
    "                        a_particle = particle['radius']\n",
    "                        phi_b_particle = particle['phi_b']\n",
    "                        \n",
    "                        if a_particle != a_target:\n",
    "                            # Retrieve the velocity source from the data DataFrame\n",
    "                            source = data.loc[data['radius'] == a_particle, 'source'].values[0]\n",
    "                            \n",
    "                            max_velocity = data.loc[data['radius'] == a_particle, 'max_velocity'].values[0]\n",
    "                            if max_velocity >= 10 * min_velocity or max_velocity == 0:\n",
    "                                # Handle inertial particles\n",
    "                                phi_w_dict[a_particle] = 0\n",
    "                            else:\n",
    "                                def objective_function(phi_w_particle):\n",
    "                                    max_velocity = max(J_brownian(a_particle, phi_w_particle, phi_b_particle,gamma_w),J_shear(a_particle, phi_w_particle, phi_b_particle,gamma_w))\n",
    "                                    return abs(max_velocity - min_velocity)\n",
    "                            \n",
    "                        #     # Minimize the objective function to find the optimal phi_w for the particle\n",
    "                                result = minimize_scalar(objective_function, bounds=(0, 0.64), method='bounded')\n",
    "\n",
    "                                if result.success:\n",
    "                                    phi_w_optimal = result.x\n",
    "                                    phi_w_dict[a_particle] = phi_w_optimal\n",
    "\n",
    "                                else:\n",
    "                                    pass\n",
    "\n",
    "                    return phi_w_dict\n",
    "\n",
    "                # Output the updated dictionary\n",
    "                #print(f\"Updated phi_w_dict: {phi_w_dict}\")\n",
    "                def packing_constraints(Particles, phi_w_list,gamma_w):\n",
    "                    ai_target, min_vel, dataf= min_flux(Particles, phi_w_list,gamma_w)\n",
    "                    phi_w_dict=calculate_phi_w(Particles, ai_target, min_vel, dataf,gamma_w)\n",
    "\n",
    "                    tolerance = 1e-6  # Set a tolerance for convergence\n",
    "                    max_iterations = 50\n",
    "                    \n",
    "                    for i in range(max_iterations):\n",
    "                        phi_w_dict_1 = {a: phi_w for a, phi_w in phi_w_dict.items() if phi_w > 0}\n",
    "\n",
    "                        max_key = max(phi_w_dict_1.keys())\n",
    "                        min_key = min(phi_w_dict_1.keys())\n",
    "                        \n",
    "                        # Check if the ratio between the max and min keys is within the thresholds\n",
    "                        if 100>(max_key / min_key )>= 10:\n",
    "                            phi_w_a1 = {a: phi_w for a, phi_w in phi_w_dict_1.items() if max_key >= a >= max_key / 10}\n",
    "                            phi_w_a2 = {a: phi_w for a, phi_w in phi_w_dict_1.items() if max_key / 10 > a >= max_key / 100}\n",
    "\n",
    "                            # Check if conditions on sums of phi_w for different ranges hold\n",
    "                            if (0.9064) >= sum(phi_w_dict.values()) and \\\n",
    "                            (sum(phi_w_a1.values()) <= 0.64) and \\\n",
    "                            (sum(phi_w_a2.values()) <= 0.74 * (1 - sum(phi_w_a1.values()))):\n",
    "                    \n",
    "                                return phi_w_dict, min_vel\n",
    "                            phi_w_previous = phi_w_dict.copy()\n",
    "                            # Update phi_w for the target particle\n",
    "                        \n",
    "                            phi_w_dict[ai_target] = (0.9064) * (phi_w_dict[ai_target] / sum(phi_w_dict.values()))\n",
    "                        \n",
    "                            ai_target, min_vel, dataf= min_flux(particles, phi_w_dict.values(),gamma_w)\n",
    "                            # min_vel = dataf.loc[dataf['radius'] == ai_target, 'max_velocity'].values[0]\n",
    "                            phi_w_dict=calculate_phi_w(particles, ai_target, min_vel, dataf,gamma_w)\n",
    "                        \n",
    "                            # Check for the change in phi_w values between iterations\n",
    "                            phi_w_diff = sum(abs(phi_w_dict[a] - phi_w_previous[a]) for a in phi_w_dict)\n",
    "                            \n",
    "                            if phi_w_diff < tolerance:\n",
    "                        \n",
    "                                return phi_w_dict,   min_vel\n",
    "                        elif (max_key / min_key )<10:\n",
    "                            \n",
    "                            if (0.68 >= sum(phi_w_dict.values())):\n",
    "                                return phi_w_dict, min_vel\n",
    "                            phi_w_previous = phi_w_dict.copy()\n",
    "                            # Update phi_w for the target particle\n",
    "                        \n",
    "                            phi_w_dict[ai_target] = (0.68* (phi_w_dict[ai_target] / sum(phi_w_dict.values())))\n",
    "                    \n",
    "                            ai_target, min_vel ,dataf= min_flux(particles, phi_w_dict.values(),gamma_w)\n",
    "                            # min_vel = dataf.loc[dataf['radius'] == ai_target, 'max_velocity'].values[0]\n",
    "                            phi_w_dict=calculate_phi_w(particles, ai_target, min_vel, dataf,gamma_w)\n",
    "                        \n",
    "                            # Check for the change in phi_w values between iterations\n",
    "                            phi_w_diff = sum(abs(phi_w_dict[a] - phi_w_previous[a]) for a in phi_w_dict)\n",
    "                            \n",
    "                            # If the change in phi_w values is smaller than the tolerance, stop the iteration\n",
    "                            if phi_w_diff < tolerance:\n",
    "                                return phi_w_dict,   min_vel\n",
    "                        elif (max_key / min_key )>=100:\n",
    "                            # Adjust the calculation for this case\n",
    "                            phi_w_a1 = {a: phi_w for a, phi_w in phi_w_dict_1.items() if max_key >= a >= max_key / 10}\n",
    "                            phi_w_a2 = {a: phi_w for a, phi_w in phi_w_dict_1.items() if max_key / 10 > a >= max_key / 100}\n",
    "                            phi_w_a3 = {a: phi_w for a, phi_w in phi_w_dict_1.items() if max_key / 100 > a }\n",
    "                        \n",
    "                            if (phi_M >= sum(phi_w_dict.values())) and \\\n",
    "                            (sum(phi_w_a1.values()) <= 0.64) and \\\n",
    "                            (sum(phi_w_a2.values()) <= 0.64 * (1 - sum(phi_w_a1.values()))) and \\\n",
    "                            sum(phi_w_a3.values()) <= 0.74 * (1 - (sum(phi_w_a1.values()) + sum(phi_w_a2.values()))):\n",
    "                                return phi_w_dict, min_vel\n",
    "                            phi_w_previous = phi_w_dict.copy()\n",
    "                            # Update phi_w for the target particle\n",
    "                        \n",
    "                            phi_w_dict[ai_target] = (phi_M * (phi_w_dict[ai_target] / sum(phi_w_dict.values())))\n",
    "                    \n",
    "                            ai_target, min_vel ,dataf= min_flux(particles, phi_w_dict.values(),gamma_w)\n",
    "                            # min_vel = dataf.loc[dataf['radius'] == ai_target, 'max_velocity'].values[0]\n",
    "                            phi_w_dict=calculate_phi_w(particles, ai_target, min_vel, dataf,gamma_w)\n",
    "                        \n",
    "                            # Check for the change in phi_w values between iterations\n",
    "                            phi_w_diff = sum(abs(phi_w_dict[a] - phi_w_previous[a]) for a in phi_w_dict)\n",
    "                            \n",
    "                            # If the change in phi_w values is smaller than the tolerance, stop the iteration\n",
    "                            if phi_w_diff < tolerance:\n",
    "                                return phi_w_dict,   min_vel\n",
    "                    return phi_w_dict, min_vel\n",
    "\n",
    "                def J_flux_calculation(Particles, phi_w_list,gamma_w):\n",
    "                    # Unpack the results from packing_constraints\n",
    "                    phi_w_dict, J_flux = packing_constraints(Particles, phi_w_list,gamma_w)\n",
    "                    # print(phi_w_dict)\n",
    "                    phi_w_dict_copy = copy.deepcopy(phi_w_dict)\n",
    "                    # Initialize J_pi with J_flux values from packing constraints for all particles\n",
    "                    J_pi = {a: J_flux for a in phi_w_dict.keys()}\n",
    "                    \n",
    "                    phi_w_dict_T = {}\n",
    "                    phi_w_dict_R = {}\n",
    "                    # Separate phi_w values into two dictionaries based on particle size comparison with p_s/2\n",
    "                    for (a, phi_w) in phi_w_dict.items():\n",
    "                        \n",
    "                        if a <= p_s / 2:\n",
    "                            phi_w_dict_T[a] = phi_w\n",
    "                            # print(phi_w_dict_T)\n",
    "                        else:\n",
    "                            phi_w_dict_R[a] = phi_w\n",
    "                            # print(phi_w_dict_R)\n",
    "\n",
    "                    # Update phi_w for particles in phi_w_dict_T based on ratio of min(phi_w_dict_R.keys()) / a\n",
    "                    for (a, phi_w) in phi_w_dict_T.items():\n",
    "                        if (min(phi_w_dict_R.keys()) / a )< 10:\n",
    "                            phi_w_dict_copy[a] = 0.64 * (1 - sum(phi_w_dict_R.values()))\n",
    "                        else:\n",
    "                            phi_w_dict_copy[a] = 0.74 * (1 - sum(phi_w_dict_R.values()))\n",
    "                    \n",
    "                    \n",
    "                    # Calculate J_pi only for particles in phi_w_dict_T\n",
    "                    for a , particle in zip(phi_w_dict_T.keys(), Particles):\n",
    "                        phi_b = particle['phi_b']\n",
    "                        \n",
    "                \n",
    "                            # Calculate velocities\n",
    "                        brownian_velocity = J_brownian(a, phi_w_dict_copy[a], phi_b, gamma_w)\n",
    "                        shear_velocity = J_shear(a, phi_w_dict_copy[a], phi_b, gamma_w)\n",
    "\n",
    "                        \n",
    "                        # Update J_pi with the maximum velocity for particles in phi_w_dict_T\n",
    "                        max_velocity = max(brownian_velocity, shear_velocity)\n",
    "                        if max_velocity< J_pi[a]:\n",
    "                            pass\n",
    "                        else:\n",
    "                            \n",
    "                            J_pi[a] = max_velocity\n",
    "                                \n",
    "                    return J_pi, phi_w_dict, J_flux\n",
    "\n",
    "                #mass-transfer coefficient calculated from equation  1#step 10\n",
    "\n",
    "\n",
    "                def sieving_parameters(Particles, phi_w_list,gamma_w):\n",
    "                    \n",
    "                    J_pi,phi_w_dict, J_flux = J_flux_calculation(Particles, phi_w_list,gamma_w)\n",
    "                    S_oi_dep = {a: (1-(J_actual / J_pi[a])) for a in phi_w_dict.keys()}\n",
    "                    S_oi_membrane = {a: 0 for a in phi_w_dict.keys()}\n",
    "                    S_oi = {a: 0 for a in phi_w_dict.keys()}\n",
    "                    for particle,phi_w in zip(Particles,phi_w_dict.values()):\n",
    "                        phi_b = particle['phi_b']\n",
    "                        a = particle['radius']\n",
    "                        if phi_w == 0:\n",
    "                            S_oi[a] = S_oi_dep[a] * S_oi_membrane[a]\n",
    "                        else:\n",
    "                        \n",
    "                            lambda_aph =lambda_aph_dict[a]\n",
    "                            # print(f\"lambda_aph: {lambda_aph}\")\n",
    "                            diffusion_coeff = (k_B * T) / (6 * math.pi * eta_f * a)\n",
    "                            mass_transfer_k = J_pi[a]/math.log(abs(phi_w/phi_b))\n",
    "                        \n",
    "                            Sieving_coeff_int = ((1 - lambda_aph) ** 2) * (2 - ((1 - lambda_aph) ** 2)) * math.exp(-0.7146 * (lambda_aph ** 2))\n",
    "                            # print(f\"Initial Sieving coefficient: {Sieving_coeff_int}\")\n",
    "                            phi_e_K_d = (1 - lambda_aph) ** (9 / 2)\n",
    "                            # print(f\"phi_e_K_d: {phi_e_K_d}\")\n",
    "                            Peclet_m = ((J_actual * (delta_membrane)) / diffusion_coeff) * (Sieving_coeff_int / (porosity * phi_e_K_d))\n",
    "                        \n",
    "                            if Peclet_m >709:\n",
    "                                Sieving_coeff_act = Sieving_coeff_int\n",
    "                            else:\n",
    "                                Sieving_coeff_act = (Sieving_coeff_int * math.exp(Peclet_m)) / ((Sieving_coeff_int + math.exp(Peclet_m)) - 1)\n",
    "                                \n",
    "                            # print(f\"Actual Sieving coefficient: {Sieving_coeff_act}\")\n",
    "                            Sieving_coeff_obs = Sieving_coeff_act / ((1 - Sieving_coeff_act) * math.exp(-J_actual / mass_transfer_k) + Sieving_coeff_act)\n",
    "                            # print(f\"Sieving coefficient: {Sieving_coeff_obs}\")\n",
    "                            S_oi_membrane[a] = Sieving_coeff_obs\n",
    "                            S_oi[a] = S_oi_dep[a] * S_oi_membrane[a]\n",
    "                            if S_oi[a] < 0 and S_oi[a] > -0.1:\n",
    "                                S_oi[a] =abs( S_oi[a])\n",
    "                            elif S_oi[a] < -0.1:\n",
    "                                S_oi[a] = 0\n",
    "                \n",
    "                    return J_flux, S_oi, phi_w_dict\n",
    "\n",
    "\n",
    "                phi_w_dict={key:values for key, values in zip([particle['radius'] for particle in particles], phi_w_guess)}\n",
    "                # Save the initial values of particles and phi_w_dict\n",
    "\n",
    "                particles_initial = copy.deepcopy(particles_copy)\n",
    "                phi_w_dict_initial = copy.deepcopy(phi_w_dict)\n",
    "                phi_b1_initial = np.array([p['phi_b'] for p in particles])  # Initial retentate concentrations\n",
    "                phi_b2_initial = np.zeros(len(particles))  # Initial permeate concentrations\n",
    "\n",
    "                total_time = 30000  # Total simulation time in seconds\n",
    "                V_2 = 300e-6  # Maximum permeate volume (mÂ³)\n",
    "                V_1 = 50e-6   # Feed volume (mÂ³)\n",
    "                V2 =0\n",
    "                # Initialize V2 globally before the simulation\n",
    "                # Initial volume of permeate in the reservoir\n",
    "                V2_max = V_2  # Maximum volume of permeate the reservoir can hold\n",
    "                time_step = 10  # Time step in seconds\n",
    "                sieving_coefficients =[]\n",
    "                times = []\n",
    "                phi_w =[]\n",
    "                J_flux_list =[]\n",
    "                # Function to calculate concentration dynamics\n",
    "                def concentration_dynamics(t, y):\n",
    "                    # phi_w_dict={key:values for key, values in zip([particle['radius'] for particle in particles], phi_w_guess)}\n",
    "                    # Split retentate and permeate concentrations\n",
    "                    N = len(particles)\n",
    "                    \n",
    "                    phi_b1 = y[:N]# Retentate concentrations\n",
    "                    phi_b2 = y[N:2*N]# Permeate concentrations\n",
    "                    V2 = y[-1]\n",
    "                    # Update particle data\n",
    "                    for i, p in enumerate(particles):\n",
    "                        p['phi_b'] = phi_b1[i]\n",
    "                    eta_f = viscosity_no_PP(eta_0, sum(p['phi_b'] for p in particles), 10)\n",
    "\n",
    "                    Q = (Re * eta_f* w )/ (rho_f )\n",
    "                    gamma_w = (6 * Q)  / ((h**2)*w)\n",
    "                \n",
    "                # Recalculate sieving coefficients and other parameters\n",
    "                    J_flux, S_oi_dict,_ = sieving_parameters(particles, phi_w_dict.values(),gamma_w)\n",
    "                    J_flux_list.append(J_flux)\n",
    "                    \n",
    "                    S_oi = np.array([S_oi_dict.get(p['radius'], 0) for p in particles]) # Extract sieving coefficients\n",
    "                    sieving_coefficients.append((S_oi))  # Append sieving coefficients for each particle\n",
    "                    times.append(t)\n",
    "\n",
    "                    phi_w.append((np.array([phi_w_dict.get(p['radius'], 0) for p in particles])))\n",
    "                    # Calculate derivatives for retentate and permeate\n",
    "                    dphi_b1_dt = np.zeros(len(particles))\n",
    "                    dphi_b2_dt = np.zeros(len(particles))\n",
    "\n",
    "                    for i, p in enumerate(particles):\n",
    "                        \n",
    "                        # Retentate dynamics\n",
    "                        dphi_b1_dt[i] = (((A * J_actual * (- S_oi[i])))* phi_b1[i])/ V_1 \n",
    "                        # Permeate dynamics\n",
    "                        dphi_b2_dt[i] = (A * J_actual * S_oi[i] * phi_b1[i]) / V_2 \n",
    "                        dV2_dt = A * J_actual\n",
    "\n",
    "                    dydt = np.concatenate([dphi_b1_dt, dphi_b2_dt, [dV2_dt]])\n",
    "                    return dydt\n",
    "\n",
    "                # Initial conditions\n",
    "                # \n",
    "                def diavolumes_event(t, y):\n",
    "                    \"\"\"Event to stop simulation when diavolumes reach 4.\"\"\"\n",
    "                    V2 = y[-1]  # Extract permeate volume from the state vector\n",
    "                    diavolumes = V2 / V_1  # Calculate diavolumes\n",
    "                    return diavolumes - 4  # Event triggers when diavolumes = 4\n",
    "                diavolumes_event.terminal = True  # Stop the solver when event occurs\n",
    "                diavolumes_event.direction = 1  # Event triggers only when increasing past 4\n",
    "                def yield_event(t, y):\n",
    "                    \"\"\"Event to stop simulation when yield reaches 95%.\"\"\"\n",
    "                    N=len(particles)\n",
    "                    phi_b2 = y[N:2*N]\n",
    "                    \n",
    "                    yield_fraction = (phi_b2 * V_2) / (phi_b1_initial * V_1)  # Calculate diavolumes\n",
    "                    target_yield = 0.95\n",
    "                    return np.max(yield_fraction)-target_yield # Event triggers when diavolumes = 4\n",
    "                yield_event.terminal = True  # Stop the solver when event occurs\n",
    "                yield_event.direction = 1  # Event triggers only when increasing past 4\n",
    "\n",
    "                V2_initial = 0\n",
    "                y0 = np.concatenate([phi_b1_initial, phi_b2_initial, [V2_initial]])\n",
    "\n",
    "                def simulate_process(J_actual):\n",
    "                    global sieving_coefficients\n",
    "                    global phi_w\n",
    "                    global J_flux_list\n",
    "\n",
    "                    # Reset global storage\n",
    "                    sieving_coefficients = []\n",
    "                    phi_w = []\n",
    "                    J_flux_list = []\n",
    "                    # Solve the system of ODEs\n",
    "                    solution = solve_ivp(\n",
    "                        concentration_dynamics,\n",
    "                        t_span=(0, total_time),\n",
    "                        y0=y0,\n",
    "                        method='RK23',\n",
    "                        t_eval=np.arange(0, total_time, time_step),\n",
    "                        rtol=1e-3,\n",
    "                        atol=1e-5,\n",
    "                        events=[diavolumes_event,yield_event],\n",
    "                            # Add events to stop simulation\n",
    "                    )\n",
    "                    \n",
    "\n",
    "                    # Extract results\n",
    "                    time_points = solution.t\n",
    "                    phi_b1_solution = solution.y[:len(particles), :].T\n",
    "                    phi_b2_solution = solution.y[len(particles):2*len(particles), :].T\n",
    "                    V2_solution = solution.y[-1, :].T\n",
    "\n",
    "                    # Calculate cumulative yield as (phi_b2 * V_2) / (phi_b1_initial * V_1)\n",
    "                    yield_fraction = (phi_b2_solution * V_2) / (phi_b1_initial * V_1)\n",
    "                \n",
    "\n",
    "                    \n",
    "                    # Store results\n",
    "                    results_df = pd.DataFrame({'Time (s)': time_points})\n",
    "                    for i, p in enumerate(particles):\n",
    "                        results_df[f'{p[\"radius\"]}_retentate'] = phi_b1_solution[:, i]\n",
    "                        results_df[f'{p[\"name\"]}_permeate'] = phi_b2_solution[:, i]\n",
    "                        results_df[f'{p[\"name\"]}_cumulative_yield'] = yield_fraction[:, i]\n",
    "                        # results_df[f'{p[\"name\"]}_sieving_coefficient'] = np.array(sieving_coefficients)[:, i]\n",
    "\n",
    "                    results_df[\"Diavolumes\"] = V2_solution / V_1\n",
    "                    # Split phi_w and sieving coefficients into separate columns in the results dataframe\n",
    "                    # Add sieving coefficients to the results dataframe\n",
    "                    sieving_df = pd.DataFrame(sieving_coefficients, columns=[f'{p[\"name\"]}_sieving_coefficient' for p in particles])\n",
    "                    sieving_df['Time (s)'] = times[:len(sieving_df)]\n",
    "                    sieving_df['J_flux'] = J_flux_list[:len(sieving_df)]\n",
    "                    phi_w_array = np.array(phi_w)\n",
    "                    for i, p in enumerate(particles):\n",
    "                        sieving_df[f'{p[\"name\"]}_phi_w' ] = phi_w_array[:len(sieving_df), i]\n",
    "                \n",
    "                    return results_df,  sieving_df\n",
    "\n",
    "\n",
    "                Re_list = list(range(120,240,20))\n",
    "\n",
    "                for i in Re_list:\n",
    "                    Re = i \n",
    "                    particles = copy.deepcopy(particles_initial)\n",
    "                    phi_w_dict={key:values for key, values in zip([particle['radius'] for particle in particles], phi_w_guess)}\n",
    "                    eta_f = viscosity_no_PP(eta_0, sum(p['phi_b'] for p in particles), 10)\n",
    "                    Q = (Re * eta_f* w )/ (rho_f )\n",
    "                    gamma_w = (6 * Q)  / ((h**2)*w)\n",
    "\n",
    "                    J_actual = 1/ 3600 / 1000\n",
    "                    J_PD, _, _ = sieving_parameters(particles, phi_w_guess,gamma_w)\n",
    "                    # print(J_PD*100)\n",
    "                    J_increment = J_PD / 5\n",
    "                    while J_actual <= J_PD*1.1:\n",
    "                        # Start timing the iteration\n",
    "                        start_time = time.time()\n",
    "\n",
    "                        # Reset particles and phi_w_dict to their initial values\n",
    "                        particles = copy.deepcopy(particles_initial)\n",
    "                        phi_w_dict = copy.deepcopy(phi_w_dict_initial)\n",
    "\n",
    "                        try:\n",
    "                            # Run the simulation\n",
    "                            results_df, sieving_df= simulate_process(J_actual)\n",
    "                            # Check if the first 4 columns contain zero\n",
    "                            column_subset = sieving_df.iloc[:, 2:5]\n",
    "                            end_time = time.time()\n",
    "                            if (end_time - start_time) > 300:\n",
    "                                print(f\"Skipping J_actual = {J_actual*3600*1000:.2f} due to time limit.\")\n",
    "\n",
    "                            elif (column_subset.eq(0).sum().max() > 10):\n",
    "                                print(f\"Skipping J_actual = {J_actual*3600*1000:.2f} due to zero columns.\")\n",
    "                            else:\n",
    "                                folder_name = f'GFP_Model_X{X:.2f}_I_{I:.2f}_pH_{pH:.2f}/GFP_Model_gamma_w_{gamma_w:.2f}_Re_{Re}_J_PD{J_PD*3600*1000:.2f}'\n",
    "                                os.makedirs(folder_name, exist_ok=True) \n",
    "                                # If not all zeros, store results\n",
    "                                results_df.to_csv(f'{folder_name}/dynamic_simulation_J_actual_{J_actual*3600*1000:.2f}_Re{Re}.csv', index=False)\n",
    "                                sieving_df.to_csv(f'{folder_name}/sieving_coefficients_J_actual_{J_actual*3600*1000:.2f}_Re{Re}.csv', index=False)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            import traceback\n",
    "                            # print(f\"Error during simulation for J_actual = {J_actual*100:.4e}: {e}\")\n",
    "                            traceback.print_exc()\n",
    "\n",
    "                        # print(f\"Iteration with J_actual = {J_actual*3600*1000} completed in {(end_time - start_time):.2f} seconds and\")\n",
    "                    \n",
    "                        \n",
    "                        if i ==1:\n",
    "                                break\n",
    "                        # Increment J_actual for the next iteration\n",
    "                        J_actual += J_increment\n",
    "                        i = 0\n",
    "                        if J_actual <1.1 * J_PD and J_actual>=J_PD:\n",
    "                            J_actual = J_PD \n",
    "                            i +=1\n",
    "\n",
    "                print(f\"Finished iteration for pH={pH}, X={X}, I={I}\")\n",
    "                            \n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
